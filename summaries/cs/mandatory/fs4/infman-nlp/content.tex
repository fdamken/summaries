\chapter{Introduction} % 11, 11.4
	Natural Language Processing is all about:
	\begin{itemize}
		\item Interpreting (creating information)
		\item Linking (supporting knowledge acquisition)
		\item Analyzing
		\item Verifying
	\end{itemize}

	\section{Language and Knowledge Processing} % 11.5, 11.6
		\begin{itemize}
			\item The World Wide Web grows about by 25 PB per day.
			\item Most of this data is unstructured.
		\end{itemize}

		\subsection{Implicit Information} % 11.7
			\begin{itemize}
				\item Data always contains \textit{implicit data}.
				\item Example: Nearly every supermarket stores information about each transaction. This data includes lots of implicit information:
					\begin{itemize}
						\item products rarely sold
						\item products often bought together
						\item \dots
					\end{itemize}
				\item Language and knowledge processing is about making this implicit information explicit.
			\end{itemize}
		% end

		\subsection{Text- and Data-Mining} % 11.9
			\begin{itemize}
				\item \textbf{Data Mining:} Exploring and analyzing large amount of data automatically to discover meaningful patterns.
					\begin{itemize}
						\item Machine learning
						\item Distributed systems, Databases
						\item Data modeling and pattern recognition
						\item Software engineering
					\end{itemize}
				\item \textbf{Text Mining:} Exploring and analyzing large amount of \textit{text} automatically to discover meaningful patterns.
					\begin{itemize}
						\item Natural Language Processing.
					\end{itemize}
			\end{itemize}
		% end

		\subsection{Examples}
			\subsubsection{Recommender Systems} % 11.8
				\begin{description}
					\item[Given] A set of items and background information about users, items, \dots.
					\item[Goal] Present the user with a subset of items that use user will like.
				\end{description}
			% end

			\subsubsection{Machine Learning (ML)} % 11.10
				\begin{description}
					\item[Given] Task, experience, performance feedback
					\item[Goal] Perform a task well, improving it with experience
				\end{description}
				\begin{itemize}
					\item A fundamental method for many text and data mining tasks.
				\end{itemize}
			% end

			\subsubsection{Document Classification} % 11.11
				\begin{description}
					\item[Given] Document, set of Topics
					\item[Goal] Find a topic in the given set of topics that describes the given document.
				\end{description}
			% end

			\subsubsection{Machine Translation (MT)} % 11.13
				\begin{description}
					\item[Given] A text in a language.
					\item[Goal] Output a text in another language with the same meaning as the given text.
				\end{description}
			% end

			\subsubsection{Speech Processing} % 11.16, 11.17
				\paragraph{Automatic Speech Recognition}
					\begin{description}
						\item[Given] Recorded voice.
						\item[Goal] Find the transcript of the given recording.
					\end{description}
				% end

				\paragraph{Speech Synthesis}
					\begin{description}
						\item[Given] Written text (transcript).
						\item[Goal] Find the corresponding acoustic signals for the given text.
					\end{description}
				% end
			% end

			\subsubsection{Information Retrieval (IR)} % 11.18
				\begin{description}
					\item[Given] A document collection and a query.
					\item[Goal] Find a subset of the documents which is maximally relevant to the query.
				\end{description}
			% end

			\subsubsection{Information Extraction (IE)} % 11.19
				\begin{description}
					\item[Given] A document collection.
					\item[Goal] Extract structured knowledge (like entities, events, relationships, \dots).
				\end{description}
			% end

			\subsubsection{Question Answering} % 11.20
				\begin{description}
					\item[Given] A natural language question and knowledge sources.
					\item[Goal] Generate an answer for the question based on the knowledge sources.
				\end{description}
			% end

			\subsubsection{Automatic Summarization} % 11.21
				\begin{description}
					\item[Given] A document collection.
					\item[Goal] Find a smaller text that summarizes the documents.
				\end{description}
				\begin{itemize}
					\item Variations
						\begin{itemize}
							\item Single- vs. Multi-document summarization
							\item Abstractive vs. Extractive summarization
							\item Indicative vs. Informative summarization
							\item General vs. Query-focused summarization
						\end{itemize}
				\end{itemize}
			% end

			\subsubsection{Sentiment Analysis and Opinion-Mining} % 11.22
				\begin{description}
					\item[Given] A text.
					\item[Goal] Separate subjective/objective opinions from objective statements; distinguish positive/negative statements; identify specific opinions and opinion targets
				\end{description}
			% end

			\subsubsection{Intelligent Computer-Assisted Language Learning (ICALL)} % 11.23
				\begin{description}
					\item[Given] Learning and a learning goal.
					\item[Goal] Assist the learning with intelligent tools.
				\end{description}
			% end
		% end
	% end

	\section{Major Scientific Challenges} % 11.24
		\subsection{Ambiguity} % 11.25
			See chapter \ref{c:linguisticpreprocessing}.

			The sentence \enquote{\ambiguity{pretty} little girl's school} can refer to:
			\begin{itemize}
				\item Very small girl going to school.
				\item Beautiful girl going to school.
				\item Very small school the girl goes to.
				\item Beautiful school the girl goes to.
			\end{itemize}
		% end

		\subsection{Underspecification and Vagueness} % 11.26
			\enquote{Alice is pretty little.}
			\begin{itemize}
				\item \( \text{height}(\text{Alice}, x) \)
				\item \( x = 0 \lor x = 3 \) is very unlikely.
				\item \( x = 1.6m \) is more likely.
			\end{itemize}

			\enquote{He usually does other things before dinner.}
			\begin{itemize}
				\item Who is \enquote{he}?
				\item What are these \enquote{other things}?
				\item What does \enquote{before dinner} mean? One hour or ten days? When is dinner time?
				\item \dots
			\end{itemize}
		% end

		\subsection{Scientific Data} % 11.29
			See chapter \ref{c:corpora}.

			Most of the NLP methods require data for
			\begin{itemize}
				\item training,
				\item development and
				\item evaluation.
			\end{itemize}
			It is often hard and expensive to obtain high-quality data, for both researchers and companies.

			For example: Find a data set with more than a million examples for good/bad arguments.
		% end

		\subsection{System Evaluation} % 11.30
			\begin{itemize}
				\item Intrinsic evaluation
					\begin{itemize}
						\item Test the method in isolation by comparing the actual output with the expected output (the so-called gold standard).
					\end{itemize}
				\item Extrinsic evaluation
					\begin{itemize}
						\item Test the method in use by embedding it into a larger system or experimental setup (e.g. a user study).
					\end{itemize}
			\end{itemize}
		% end
	% end
% end

\chapter{Natural Language Text} % 12.1, 12.3
	\begin{description}
		\item[Alphabet] \( \Sigma = \{ A, B, C, \cdots, a, b, c, \cdots, 0, 1, \cdots \} \)
		\item[Characters] \( s'\in \Sigma \)
		\item[String] \( s = s_1 \cdots s_n \in \Sigma^* \)
		\item[Message] A string that follows a grammar.
		\item[Data] An exchanged message that is not yet interpreted.
		\item[Text] Written coherent data of a language.
		\item[Coherence] Coherence is what makes a text semantically meaningful and connects the ideas arranged in a text.
	\end{description}

	\section{Scripts and Language} % 12.4
		\begin{itemize}
			\item Script
				\begin{itemize}
					\item Defines the symbol set \( \Sigma \).
					\item \textit{Alphabetic} scripts: Latin, Greek, Cyrillic, \dots
					\item \textit{Logographic} or syllabic: Hanzi (Chinese), Kanji, Katakana, \dots
					\item Consonant-Based (\textit{Abjab}): Arabic, Hebrew, \dots
					\item Segment-based (\textit{Abugida}): Devanagari, Tibetan, Indic, \dots
					\item Writing direction: left-to-right, right-to-left, top-to-bottom, bottom-to-top, \dots
				\end{itemize}
			\item Language
				\begin{itemize}
					\item Determines the grammar and the vocabulary.
					\item Examples: English, German, Japanese, Spain, \dots
				\end{itemize}
		\end{itemize}
	% end

	\section{Properties of Text} % 12.5
		\begin{itemize}
			\item \textbf{Text type/Genre:} textbook, scientific paper, news item, social media post, \dots
			\item \textbf{Register:} language variety (dialect, jargon, formal, \dots)
			\item \textbf{Style:} how the text is written (e.g. funny, political, scientific, \dots)
			\item \textbf{Domain/topic:} biology, information science, education, spacecrafts, \dots
			\item \textbf{Time} of writing as languages change during time
		\end{itemize}

		\subsection{Structure} % 12.6
			\begin{figure}[H]
				\centering
				\begin{tikzpicture}[node distance = 0.5, every node/.style = { draw, rectangle, minimum height = 0.8cm, minimum width = 3.5cm }]
					\node (a) {Chapter / Section};
					\node [below = of a] (b) {Paragraph};
					\node [below = of b] (c) {Sentence};
					\node [below = of c] (d) {Phrase};
					\node [below = of d] (e) {Word};
					\node [below = of e] (f) {Letter/Character};

					\draw (a) -- (b) -- (c) -- (d) -- (e) -- (f);
				\end{tikzpicture}
			\end{figure}
		% end
	% end

	\section{Examples of electronic Text Formats} % 12.7
		\begin{itemize}
			\item Mostly unstructured
				\begin{itemize}
					\item Plain text
				\end{itemize}
			\item Semi-structured
				\begin{itemize}
					\item Hypertext markup language (HTML)
					\item Extensible markup language (XML)
				\end{itemize}
			\item XML-based formats
				\begin{itemize}
					\item Open document format (ODT)
					\item Word files (DOCX)
				\end{itemize}
			\item Binary content
				\begin{itemize}
					\item Word files (DOC)
				\end{itemize}
			\item Mixed text and binary content
				\begin{itemize}
					\item Rich text (RTF)
					\item Portable document format (PDF)
				\end{itemize}
		\end{itemize}

		\subsection{Text in relational Databases} % 12.8
			\begin{itemize}
				\item It is also possible to store large amount data in a relational database.
				\item \lstinline|CHAR|\((n)\) and \lstinline|VARCHAR|\((n)\) can only store up to \(n\) characters with typically \( n \leq 4000\cdots8000 \).
				\item A lot more text with more or less arbitrary length can be saved using:
					\begin{itemize}
						\item Binary large objects (BLOBs)
						\item Character large objects (CLOBs)
					\end{itemize}
				\item The size limit for these data types are mostly infinite with ranging from 2 GB to more that 128 TB.
				\item But in most DBs it is not possible to do sorting/group and comparing is limited to the most basic (\lstinline|=|, \lstinline|BETWEEN|, \dots).
			\end{itemize}
		% end
	% end

	\section{Character Encoding} % 12.9, 12.11, 12.13
		\begin{itemize}
			\item As databases can only store 1s and 0s a character encoding is needed:
				\begin{align*}
					\text{enc} & : \Sigma^* \rightarrow \{ 0, 1 \}^* \tag{Encoding} \\
					\text{dec} & : \{ 0, 1 \}^* \rightarrow \Sigma^* \tag{Decoding}
				\end{align*}
			\item Typically each character is mapped onto a bit mask using a character set \( \Psi : \Sigma \rightarrow \{ 0, 1 \}^* \), so a text \( T = c_1 \cdots c_n \in \Sigma^* \) is encoding as \( \text{enc}(T) = \Psi(c_1)\cdots\Psi(c_n) \)
			\item There are several base categories of encoding:
				\begin{itemize}
					\item \textbf{Single byte} \\ Each character corresponds to a single byte (8 Bit).
					\item \textbf{Multi byte} \\ Each character corresponds to a fixed number of bytes.
					\item \textbf{Variable-length} \\ The bit length of each character might change depending on the character.
					\item \textbf{Escape-code-based} \\ Switch between different character sets using escape codes.
				\end{itemize}
		\end{itemize}

		\subsection{Encoding Issues in Software and Databases} % 12.22, 12.23
			\begin{itemize}
				\item Key question when working with text: Which encoding does the text use?
				\item Key question when programming: Default encoding of source files? Default encoding of string types? Default encoding when reading/writing a file?
				\item Key questions when working with databases: Default encoding of a table? Default encoding of the database connection?
				\item Example Issues
					\begin{itemize}
						\item String length of variable-length encodings
						\item String operations
						\item String searching
						\item Sort strings alphabetically
					\end{itemize}
			\end{itemize}

			\subsubsection{Sorting} % 12.24, 12.25, 12.26
				\begin{itemize}
					\item \textbf{Order of Characters}
						\begin{itemize}
							\item Latin script: A < B < \dots < Y < Z
							\item Chinese: How to sort? By number of strokes?
						\end{itemize}
					\item \textbf{Case}
						\begin{itemize}
							\item Binary sort: A < B < \dots < a < b < \dots
							\item Alternatives: \ambiguity{A = a} < B vs. \ambiguity{A < a} < B
							\item Turkish: \texttt{istanbul} = \texttt{iSTANBUL}
							\item German: \texttt{istanbul} = \texttt{ISTANBUL}
						\end{itemize}
					\item \textbf{Transliteration}
						\begin{itemize}
							\item Greek: \( \alpha < \beta < \gamma < \delta \)
							\item German: a < b < \ambiguity{g???} < d
						\end{itemize}
					\item \textbf{Equivalent Characters}
						\begin{itemize}
							\item German (dictionary, DIN 5007-1): n < \ambiguity{o} = \ambiguity{ö} < p
							\item Finnish: n < \ambiguity{o} < p < \dots < z < ä < \ambiguity{ö}
						\end{itemize}
					\item \textbf{Diacritics}
						\begin{itemize}
							\item e < {\'e} < f vs. e = {\'e} < f
							\item French: c{\^o}te < cot{\'e}
							\item English: cot{\'e} < c{\^o}te
						\end{itemize}
					\item \textbf{Character Combinations}
						\begin{itemize}
							\item German (phonebook, DIN 5007-2): n < o [ö = oe] < p
							\item Spanish (traditional): ce < cu < ch < da
							\item Danish: z < \ae \, < \! \oe \, = \o \, = ö < \(\mathring{\text{a}}\)
						\end{itemize}
				\end{itemize}
			% end

			\subsubsection{Collation Framework} % 12.27
				The collation\dots
				\begin{itemize}
					\item is the definition of a sort order,
					\item is available for multiple language, e.g. German and
					\item there are variants for sorting, e.g. lexical, phone book, traditional vs. modern, \dots
				\end{itemize}
			% end
		% end

		\subsection{Example Encodings} % -
			\subsubsection{ASCII} % 12.10
				See \HREF{https://www.asciitable.com}.
			% end

			\subsubsection{Unicode} % 12.14, 12.15, 12.16, 12.17
				\begin{itemize}
					\item The idea was to define one character set that covers all characters observed in the world including:
						\begin{itemize}
							\item logographic languages
							\item fantasy languages
							\item currency symbols
							\item emoji characters
							\item \dots
						\end{itemize}
					\item Unicode 14.0 defines 144,697 characters, 159 writing systems and 3633 emojis.
					\item Each character has 4 bytes with currently 21 significant bits.
				\end{itemize}

				\paragraph{Architecture}
					\begin{itemize}
						\item Overall count of 1,114,112 code points ranging from \texttt{0x000000} to \texttt{0x10FFFF}.
						\item The notation is \texttt{U+ppxxxx}.
						\item \texttt{pp} subdivides the code into 17 planes (from \texttt{0x00} to \texttt{0x10}).
						\item The plane \( \texttt{pp} = 0 \) is called the \textit{Basic Multilingual Plane} (BMP) and contains the most commonly used characters:
							\begin{itemize}
								\item Latin, Greek, Cyrillic
								\item Arabic, Hebrew
								\item Most of the Chinese, Japanese and Korean languages (CJK)
								\item \dots
							\end{itemize}
						\item Other planes are:
							\begin{description}
								\item[Plane 1] Supplementary Multilingual Plane (SMP) \\ Historic languages
								\item[Plane 2] (Supplementary Ideographic Plane) (SIP) \\ Extensions for Chinese, Japanese, Korean
								\item[Plane 3-13] Empty
								\item[Plane 14] Supplementary Special-purpose Plane (SSP) \\ Control characters (e.g. language tags)
								\item[Plane 15-16] Supplementary Private Use Area (PUA-A/B) \\ Reserved for private characters of a certain font
							\end{description}
					\end{itemize}
				% end
			% end

			\subsubsection{UTF-32/UCS-4} % 12.18
				\begin{itemize}
					\item Each character is encoded with exactly 4 bytes.
					\item Directly corresponds to Unicode.
					\item Disadvantages:
						\begin{itemize}
							\item Wastes disk space and memory, 4 times the size of ISO 8859-1.
							\item This might yield to longer processing times.
						\end{itemize}
				\end{itemize}
			% end

			\subsubsection{UCS-2} % 12.19
				\begin{itemize}
					\item Each character is encoded with exactly 2 bytes.
					\item Directly corresponds to the Unicode BMP.
				\end{itemize}
			% end

			\subsubsection{UTF-16} % 12.20
				\begin{itemize}
					\item Each character is encoded with 2 to 4 bytes.
					\item Directly corresponds to the Unicode BMP.
					\item Divides characters of supplementary planes into a so-called high and low surrogate.
					\item Surrogates: Subtract \texttt{0x10000} and divide into upper/lower 10 bits.
				\end{itemize}
			% end

			\subsubsection{UTF-8} % 12.21
				\begin{itemize}
					\item Each character is encoded with 1 to 4 bytes.
					\item Directly corresponds to ASCII.
					\item Non-ASCII characters use additional bytes.
					\item Theoretically it is possible to extend the code to 6 bytes.
				\end{itemize}
			% end
		% end
	% end
% end

\chapter{Linguistic Preprocessing} % 13
	\label{c:linguisticpreprocessing}

	\section{Segmention} % 13.3, 13.4
		\begin{figure}[H]
			\centering
			\texttt{The | dwarfs | loved | her | dearly}
		\end{figure}

		\subsection{Tokenization} % 13.5, 13.6
			\begin{itemize}
				\item The task of \textit{tokenization} is to segment an input stream into an ordered sequence of tokens.
				\item Most of the time, \textit{tokens} correspond to inflected word forms.
				\item The system for segmenting the input stream is called \textit{tokenizer}.
				\item Naive approach: split on whitespaces.
					\begin{itemize}
						\item This leads to multiple problems, for instance with the following sentence: \\ Mr. Sherwood said, reaction to Sea Containers' proposal has been \enquote{very positive.}
						\item Splitting on whitespaces gives the following false tokens:
							\begin{itemize}
								\item \verb$said,$
								\item \verb$"very$
								\item \verb$positive."$
							\end{itemize}
						\item Thus, splitting on whitespaces is not a solution.
					\end{itemize}
			\end{itemize}

			\subsubsection{Ambiguities} % 13.7, 13.8, 13.9
				\begin{itemize}
					\item Periods
						\begin{itemize}
							\item In most cases, a period represents a sentence termination \( \implies \) separate tokens.
							\item But sometimes, it is part of a token:
								\begin{itemize}
									\item abbreviations (e.g. \texttt{e.g.})
									\item Ordinal numbers (e.g. \texttt{21.}), fractions (e.g. \texttt{12.34})
									\item references to resource locators (e.g. \texttt{www.twitter.com})
								\end{itemize}
						\end{itemize}
					\item Comma
						\begin{itemize}
							\item Part of numbers (e.g. \texttt{1,234}) \( \implies \) part of token.
						\end{itemize}
					\item Whitespace
						\begin{itemize}
							\item Part of numbers (e.g. \texttt{1 234}) \( \implies \) part of token.
						\end{itemize}
					\item Single Quote
						\begin{itemize}
							\item In some cases, it is an enclosing quote (e.g. \texttt{\enquote{You asked 'why',} he said.}) \(\implies\) separate tokens.
							\item In contractions or elisions (e.g. \texttt{don't}, \texttt{James' book}) \(\implies\) should it be a part of the token or a separate token?
						\end{itemize}
					\item Dash
						\begin{itemize}
							\item In most cases, it is part of a token (e.g. \texttt{part-time job}).
							\item But it may be part of ranges (e.g. \texttt{see page 100-102}) \(\implies\) may be separate tokens.
						\end{itemize}
					\item Colon
						\begin{itemize}
							\item In most cases, it is a sentence delimiter \(\implies\) separate tokens.
							\item But it may be part of expressions (e.g. \texttt{12:30}) \(\implies\) part of a token.
						\end{itemize}
					\item And many, many other ambiguities\dots
				\end{itemize}
			% end
		% end

		\subsection{Segmention in other Languages} % 13.10
			\begin{itemize}
				\item In Chinese, there are no spaces.
				\item Beyond that, sentences may have completely different meanings when splitting on the wrong position. Chinese is context-sensitive.
			\end{itemize}
		% end

		\subsection{Software} % 13.11
			\begin{itemize}
				\item \textbf{Stanford CoreNLP and Word Segmenter} (Java)
				\item \textbf{OpenNLP Tokenizer} (Java)
				\item \textbf{LanguageTool Segmenter} (Java)
				\item \textbf{DKPro Core} (Java)
				\item \textbf{Natural Language Processing Toolkit (NLTK)} (Python)
			\end{itemize}
		% end
	% end

	\section{Morphology} % 13.12, 13.13, 13.14, 13.15
		\begin{itemize}
			\item Morphology is about how single words are composed and is the study of word forms and word formation.
			\item Single words are composed of morphemes.
			\item \textit{Morphemes} are the smallest unit a word can be split into.
			\item For instance:
		\end{itemize}

		\Tree[.{ The dwarfs loved her dearly }
			[.The
				The
			]
			[.dwarfs
				dwarf
				s
			]
			[.loved
				lov
				ed
			]
			[.her
				her
			]
			[.dearly
				dear
				ly
			]
		]

		\subsection{Bases and Affixes} % 13.17
			\begin{itemize}
				\item Free morpheme
					\begin{itemize}
						\item Morphemes that can appear in isolation.
						\item Example: Both words \enquote{cat} and \enquote{cats} can appear in isolation.
					\end{itemize}
				\item Bound morpheme, affix
					\begin{itemize}
						\item Morphemes that can not appear in isolation, like the suffix \enquote{-s} in \enquote{cats}.
						\item These are often used for inflection (plural, 3rd person singular, past, \dots).
					\end{itemize}
				\item Bases, stems
					\begin{itemize}
						\item The minimal free morpheme of a word is called the \textit{stem} of the word.
						\item These stems carry the main meaning of the word.
						\item Example: The stem of \enquote{cats} is \enquote{cat}.
					\end{itemize}
			\end{itemize}

			\subsubsection{Types of Affixes} % 13.18
				\begin{description}
					\item[Suffix] Appears after the base. \\ Example: \enquote{cat + \ambiguity{s}}
					\item[Prefix] Appears before in the base. \\ Example: \enquote{\ambiguity{un} + true}
					\item[Infix] Appears inside the base. \\ Example: \enquote{fan + \ambiguity{bloody} + tastic}
					\item[Circumfix] Appears around (on both sides of) the base. \\ Example: \enquote{\ambiguity{ge} + sag + \ambiguity{t}}
				\end{description}
			% end
		% end

		\subsection{Classification of Morphemes} % 13.19
			\Tree[.{Morphemes}
				[.{Free Morphemes}
					[.{Open Class Words}
						{Nouns\\Verbs\\Adjectives\\Adverbs}
					]
					[.{Closed Class Words}
						{Conjunctions\\Determiners\\Prepositions\\\dots}
					]
				]
				[.{Bound Morphemes}
					[.{Affixes}
						{Prefixes}
						{Suffixes}
						{Infixes}
						{Circumfixes}
					]
					[.{Contracted Forms}
						{-'ll\\-'d\\\dots}
					]
				]
			]

			\subsubsection{Morphological Analysis} % 13.20
				\Tree[.Lösbarkeitsprobleme
				[.Lösbarkeitsproblem
				[.Lösbarkeit
				[.lösbar
				{Lös \\ (Stem)}
				{-bar \\ (Suffix)}
				]
				{-keit \\ (Suffix)}
				]
				{Problem \\ (Stem)}
				]
				{-e \\ (Plural Suffix)}
				]
			% end
		% end

		\subsection{Word Formation} % 13.21
			\begin{description}
				\item[Derivation] Forming new words from a free morpheme and an affix.
				\item[Conversion] Also called \textit{zero derivation}; Forming new words by changing the meaning of a word an affix, for example by modifying the stem. \\ Example: to talk \(\rightarrow\) a talk; to host a party \(\rightarrow\) the host; \dots
				\item[Composition] Also called \textit{compounding}; Forming new words by combining multiple free morphemes and linking elements.
			\end{description}

			\subsubsection{Decompounding} % 13.22
				\begin{itemize}
					\item Splitting compounds into the creating parts.
					\item Example: \enquote{Bücherregale} \(\rightarrow\) Bücher + Regale
					\item This may be complicated as splitting on different positions may lead to different meanings:
						\begin{itemize}
							\item Kult\ambiguity{ur}teilen \(\rightarrow\) Kult\ambiguity{ur} + teilen
							\item Kult\ambiguity{ur}teilen \(\rightarrow\) Kult + \ambiguity{ur}teilen
						\end{itemize}
				\end{itemize}
			% end
		% end

		\subsection{Morphology in other Languages} % 13.23
			\begin{itemize}
				\item In Turkish, only affixes are combined to form complete words.
				\item This is extremely hard to split.
			\end{itemize}
		% end

		\subsection{Morphological Normalization} % 13.24
			Normalizing a word is about to find a single canonical representation of a word. This gives multiple approaches:
			\begin{itemize}
				\item Stemming
				\item Lemmatization
				\item Morphological analysis
			\end{itemize}

			\subsubsection{Stemming} % 13.25, 13.26
				\begin{itemize}
					\item Algorithmic approach to bring any word in its stemmed form.
					\item Words with the same morphological family should end up in similar stems.
					\item Stemming does not differentiate between stemming and derivation.
					\item The stemmed results may not be genuine word forms!
					\item Examples (Porter's Stemmer):
						\begin{table}[H]
							\centering
							\begin{tabular}{l c l}
								\textbf{Original} &                 & \textbf{Stemmed Word} \\
								visible           & \(\rightarrow\) & visibl                \\
								visibility        & \(\rightarrow\) & visibl                \\
								vision            & \(\rightarrow\) & vision                \\
								visionary         & \(\rightarrow\) & visionari             \\
								visioner          & \(\rightarrow\) & vision                \\
								visual            & \(\rightarrow\) & visual
							\end{tabular}
						\end{table}
				\end{itemize}

				\paragraph{Errors} % 13.27
					\begin{description}
						\item[Under-stemming] The stemmer does not transform related word to the same stem.
							\begin{itemize}
								\item adhere \(\rightarrow\) adhe\ambiguity{r}
								\item adhesion \(\rightarrow\) adhe\ambiguity{s}
							\end{itemize}
						\item[Over-stemming] The stemmer can not distinguish between actual different words.
							\begin{itemize}
								\item appendicitis \(\rightarrow\) append
								\item append \(\rightarrow\) append
							\end{itemize}
					\end{description}
				% end

				\paragraph{Ambiguity: Homographs} % 13.28
					\begin{itemize}
						\item There are words that have different meanings, like:
							\begin{itemize}
								\item Saw - The singular form of the noun \enquote{saw}.
								\item Saw - The past form of the present verb \enquote{see}.
							\end{itemize}
						\item It is not possible to handle these cases with stemming only, the word category (noun, verb, adverb, \dots) also has to be identified.
					\end{itemize}
				% end
			% end

			\subsubsection{Lemmatization} % 13.29
				\begin{itemize}
					\item \enquote{Undo} the inflection changes and determine the actual base form.
					\item This typically requires information about the part of speech:
						\begin{itemize}
							\item Verb: \tabto{1.5cm} left \(\rightarrow\) leave \tabto{5cm} saw \(\rightarrow\) see
							\item Noun: \tabto{1.5cm} left \(\rightarrow\) left  \tabto{5cm} saw \(\rightarrow\) saw
						\end{itemize}
					\item Lemmatization has to deal with irregular forms:
						\begin{itemize}
							\item sing, sang, sung \(\rightarrow\) sing
							\item indices \(\rightarrow\) index
							\item Bäume \(\rightarrow\) Baum
						\end{itemize}
				\end{itemize}
			% end

			\subsubsection{Stemming, Lemmatization, Morphological Analysis} % 13.30
				\begin{table}[H]
					\centering
					\begin{tabular}{l l l l}
						\textbf{Original} & \textbf{Stemmed} & \textbf{Lemmatized} & Analysis \\
						visibilities      & visibl           & visibility          & +PL      \\
						adhere            & adher            & adhere              &          \\
						adhesion          & adhes            & adhesion            &          \\
						appendicitis      & append           & appendicitis        & +PL      \\
						oxen              & oxen             & ox                  & +PL      \\
						indices           & indic            & index               & +PL      \\
						swum              & swum             & swim                & +PP
					\end{tabular}
				\end{table}
			% end
		% end

		\subsection{Software} % 13.32
			\begin{itemize}
				\item \textbf{Stanford CoreNLP} (Java)
				\item \textbf{SMOR Morphological Analysis for German}
				\item \textbf{Language Tool Lemmatizer} (Java)
				\item \textbf{DKPro Core} (Java)
				\item \textbf{Natural Language Processing Toolkit (NLTK)} (Python)
			\end{itemize}
		% end
	% end

	\section{Syntax} % 13.33, 13.34
		\begin{itemize}
			\item The \textit{Syntax} refers to the way multiple words are arranged together.
			\item There are infinite way to form word together to make up a sentence.
			\item Humans can understand most sentences they never heard before.
		\end{itemize}

		\subsection{Part of Speech Tagging (POS Tagging)} % 13.35
			\begin{itemize}
				\item POS tagging is the process of assigning each word of a text its lexical class:
					\begin{equation*}
						\underbrace{\text{The}}_\text{Determiner} \quad \underbrace{\text{dwarfs}}_\text{Noun} \quad \underbrace{\text{loved}}_\text{Verb} \quad \underbrace{\text{her}}_\text{Pronoun} \quad \underbrace{\text{dearly}}_\text{Adjective}
					\end{equation*}
			\end{itemize}

			\subsubsection{Parts of Speech} % 13.36, 13.39
				\begin{itemize}
					\item The most commonly used word classes are:
						\begin{description}
							\item[N] Noun
							\item[V] Verb
							\item[ADJ] Adjective
							\item[ADV] Adverb
							\item[P] Preposition
							\item[PRO] Pronoun,
							\item[DET] Determiner
						\end{description}
					\item These so-called \textit{tagsets} differ for every language and may be really fine-grained or rough.
					\item Common tagset sizes:
						\begin{itemize}
							\item English: 139
							\item Czech: 970
							\item Estonian: 476
							\item Hungarian: 401
							\item Romanian: 486
							\item Slovene: 1033
						\end{itemize}
					\item Data that is POS-tagged provides valuable information about:
						\begin{itemize}
							\item the word formation \( \rightarrow \) lemmatization, morphological analysis
							\item a word and its possible neighbors \( \rightarrow \) language models
							\item the correct pronunciation \( \rightarrow \) speech synthesis
							\item its intended sense \( \rightarrow \) word sense disambiguation
							\item the meaning of a sentence \( \rightarrow \) shallow parsing
						\end{itemize}
					\item Example:
						\begin{table}[H]
							\centering
							\begin{tabular}{l l l}
								\textbf{Word} & \textbf{Lemmatized} & \textbf{POS-Tag} \\
								the           & the                 & +DET             \\
								girl          & girl                & +NOUN            \\
								kissed        & kiss                & +VPAST           \\
								the           & the                 & +DET             \\
								boy           & boy                 & +NOUN            \\
								on            & on                  & +PREP            \\
								the           & the                 & +DET             \\
								cheek         & cheek               & +NOUN
							\end{tabular}
						\end{table}
				\end{itemize}

				\paragraph{Example Tagsets} % 13.37, 13.38
					\begin{itemize}
						\item Penn Treebank Tagset: \HREF{http://www.clips.ua.ac.be/pages/mbsp-tags}
						\item Stuttgart-Tübingen Tagset: \HREF{http://www.ims.uni-stuttgart.de/forschung/ressourcen/lexika/TagSets/stts-table.html}
					\end{itemize}
				% end

				\paragraph{Ambiguity} % 13.41
					\begin{itemize}
						\item Often one word may have multiple possibilities for the POS-tag:
							\begin{itemize}
								\item The \ambiguity{back} door is open. \( \rightarrow \) ADJ
								\item Peter has a scan on his \ambiguity{back}. \( \rightarrow \) NOUN
								\item She tried to win the voters \ambiguity{back}. \( \rightarrow \) ADVERB
								\item He promised to \ambiguity{back} the bill. \( \rightarrow \) VERB
							\end{itemize}
					\end{itemize}
				% end
			% end

			\subsubsection{Approaches to  POS Tagging} % 13.42
				\begin{itemize}
					\item Rule-based Tagging
						\begin{itemize}
							\item Create a dictionary word form \(\rightarrow\) POS tags.
							\item Then apply or automatically learn transformation rules to improve accuracy.
							\item For yet unknown words, use the most frequent POS tag (e.g. NOUN).
						\end{itemize}
					\item Probabilistic Tagging
						\begin{itemize}
							\item Estimate the probability that a word has a specific tag \( \rightarrow \) assign the tag with the highest probability.
							\item Probabilities are learned from manually labeled data.
						\end{itemize}
				\end{itemize}
			% end

			\subsubsection{Software} % 13.43
				\begin{itemize}
					\item \textbf{Stanford CoreNLP} (Java)
					\item \textbf{TreeTagger}
					\item \textbf{Mate Tools} (Java)
					\item \textbf{DKPro Core} (Java)
					\item \textbf{Natural Language Processing Toolkit (NLTK)} (Python)
				\end{itemize}
			% end
		% end

		\subsection{Parsing} % 13.44
			Parsing is about determining the grammatical structure of a sentence.

			\Tree[.{The dwarfs loved her dearly}
				[.{The dwarfs}
					The
					dwarfs
				]
				[.{loved her dearly}
					loved
					her
					dearly
				]
			]

			\subsubsection{Phrase Structure Grammars} % 13.45
				\begin{itemize}
					\item The \textit{phase structure grammar} is about representing a sentence by decomposing it into its constituents.
					\item A \textit{constituent} is a group of words that behaves like a single unit. In phrase structure grammars, these are mostly phrases. \\ Tests are used to identify constituents:
						\begin{itemize}
							\item Example: The dog ate \ambiguity{a cookie}.
							\item \textit{Substitution:} The dog ate \ambiguity{it}.
							\item \textit{Movement:} \ambiguity{A cookie} was eaten by the dog.
							\item \textit{Coordination:} The dog ate \ambiguity{a cookie} and a sausage.
							\item \textit{Question:} What did the dog eat? \ambiguity{A cookie}.
						\end{itemize}
				\end{itemize}
			% end

			\subsubsection{Phrase Types} % 13.46
				\begin{description}
					\item[Noun Phrase (NP)] Noun as head. \\ Example: \enquote{the black \ambiguity{cat}}; \enquote{a \ambiguity{cat} on the mat}
					\item[Prepositional Phrase (PP)] Preposition as head. \\ Example: \enquote{\ambiguity{in} love}; \enquote{\ambiguity{over} the rainbow}
					\item[Verb Phrase (VP)] Verb as head. \\ Example: \enquote{\ambiguity{eat} cheese}; \enquote{\ambiguity{jump} up and down}
					\item[Adjectival Phrase (AP)] Adjective as head. \\ Example: \enquote{\ambiguity{full} of toys}; \enquote{\ambiguity{fraught} with guilt}
					\item[Adverbial Phrase (AdbP)] Adverb as head. \\ Example: \enquote{\ambiguity{dearly}}; \enquote{very \ambiguity{carefully}}
				\end{description}
				\begin{itemize}
					\item The \textit{phrase head} determines the syntactical type of the sentence.
					\item A \textit{grammatical modifier} is an optional element of a phrase.
						\begin{itemize}
							\item \enquote{Modifies} the meaning (e.g. \enquote{the ball} vs. \enquote{the red ball}).
							\item A \textit{premodifier} appears in front of the head.
							\item A \textit{postmodifier} appears after the head.
							\item These are often adjectives, adverbs, prepositional phrases, \dots
						\end{itemize}
				\end{itemize}
			% end

			\subsubsection{Phrase Parsing} % 13.48
				\begin{itemize}
					\item For a given sentence, check if it can be generated by a given grammar.
					\item Sentences that can be generated by a grammar are called \textit{grammatical sentences}.
					\item \textit{Ungrammatical sentences} are unacceptable/uninterpretable with respect to the grammar.
					\item Even more important than that can it be generated by a grammar is, how can it be generated? That is, how can a sentence be decomposed into phrases.
					\item This step produces a \textit{parse tree}.
				\end{itemize}

				\paragraph{Parse Tree} % 13.49
					The following is the parse tree for the sentence \enquote{the dog ate a cookie}.

					\Tree[.S
						[.NP
							[.DET
								the
							]
							[.N
								dog
							]
						]
						[.VP
							[.V
								ate
							]
							[.NP
								[.DET
									a
								]
								[.N
									cookie
								]
							]
						]
					]
				% end

				\paragraph{Alternative Notations} % 13.50
					\begin{itemize}
						\item Bracket notation:
							\begin{equation*}
								[_\text{S} \, [_\text{NP} \, [_\text{DET} \, \text{the}] \, [_N \, \text{dog} ]] \, [_\text{VP} \, [_\text{V} \, \text{ate} ] \, [_\text{NP} \, [_\text{DET} \, \text{a}] \, [_\text{N} \, \text{cookie} ]]]]
							\end{equation*}
						\item Parenthesized notation:
							\begin{lstlisting}[numbers = none]
(S
	(NP
		(DET the)
		(N dog) )
	(VP
		(V ate)
		(NP
			(DET a)
			(N cookie) ) ) )
                    		\end{lstlisting}
					\end{itemize}
				% end
			% end

			\subsubsection{Context-Free Grammars (CFG)} % 13.51, 13.52
				Context-free grammar \( G = (T, N, S, R) \) with:
				\begin{itemize}
					\item Terminals \(T\),
					\item Non-terminals \(N\),
					\item Start symbol \(S\) and
					\item production rules \(R\) with elements in the form \( X \rightarrow \gamma \), where \( X \in N \) and \( \gamma \in (T \cup N)^* \).
				\end{itemize}
				The grammar \(G\) generates language \(L(G)\).
			% end

			\subsubsection{Syntactical Ambiguity} % 15.54, 13.55, 13.56
				Sometimes a sentence has more than one valid syntactical structure.
				\begin{itemize}
					\item \textbf{Attachment Ambiguity:} A constituent can be added to the parse tree at different locations. \\ Example:
						\begin{itemize}
							\item \enquote{I shot an elephant in my pants.}
							\item[] \( \overset{A?}{\implies} \) VP \(\rightarrow\) VP NP \( \implies \underbrace{\text{I shot}}_{\text{VP}} \underbrace{\text{an elephant in my pants.}}_{\text{NP}} \)
							\item[] \( \overset{B?}{\implies} \) VP \(\rightarrow\) NP NP \( \implies \underbrace{\text{I shot an elephant}}_{\text{NP}} \underbrace{\text{in my pants.}}_{\text{NP}} \)
						\end{itemize}
					\item \textbf{Coordination Ambiguity:} Varying scope of the conjunction. \\ Example:
						\begin{itemize}
							\item \enquote{Black cats and dogs like to play.}
							\item[] \( \overset{A?}{\implies} \) NP \(\rightarrow\) AP VP \( \underbrace{\text{Black cats and dogs}}_{\text{AP}} \underbrace{\text{like to play.}}_{\text{VP}} \)
							\item[] \( \overset{B?}{\implies} \) NP \(\rightarrow\) AP NP VP \( \underbrace{\text{Black cats}}_{\text{AP}} \underbrace{\text{and dogs}}_{\text{NP}} \underbrace{\text{like to play.}}_{\text{VP}} \)
						\end{itemize}
					\item \textbf{Garden path sentence:} A grammatical sentence where it is not possible to apply obvious grammatical rules.
						\begin{itemize}
							\item \enquote{The old man the boat.}
						\end{itemize}
				\end{itemize}

				\paragraph{Example: Attachment Ambiguity}
					\enquote{I saw the man with a telescope.}

					\Tree[.S
						[.NP
							[.PRP
								\textit{I}
							]
						]
						[.VP
							[.V
								[.VBD
									\textit{saw}
								]
							]
							[.NP
								[.NP
									[.DT
										\textit{the}
									]
									[.NN
										\textit{man}
									]
								]
								[.PP
									[.IN
										\textit{with}
									]
									[.NP
										[.DT
											\textit{a}
										]
										[.NN
											\textit{telescope}
										]
									]
								]
							]
						]
					]

					\Tree[.S
						[.NP
							[.PRP
								\textit{I}
							]
						]
						[.VP
							[.V
								[.VBD
									\textit{saw}
								]
							]
							[.NP
								[.DT
									\textit{the}
								]
								[.NN
									\textit{man}
								]
							]
							[.PP
								[.IN
									\textit{with}
								]
								[.NP
									[.DT
										\textit{a}
									]
									[.NN
										\textit{telescope}
									]
								]
							]
						]
					]
				% end
			% end

			\subsubsection{Dependency Grammar} % 13.57
				\begin{itemize}
					\item A \textit{dependency grammar} is a different kind of syntactic representation.
					\item Not based on phrases but on binary relations between words:
						\begin{equation*}
							\textit{grammatical-function}(\textbf{\ambiguity{\text{head}}}, \underline{\ambiguity{\text{dependent}}})
						\end{equation*}
					\item Examples:
						\begin{itemize}
							\item Subject: \enquote{\ambiguity{\underline{Sue}} \ambiguity{\textbf{watched}} the man at the next table.}
							\item Direct Object: \enquote{Sue \ambiguity{\textbf{watched}} the \ambiguity{\underline{man}} at the next table.}
							\item Determiner: \enquote{Sue watched \ambiguity{\underline{the}} \ambiguity{\textbf{man}} at the next table.}
							\item \dots
						\end{itemize}
					\item Abstract from word order.
				\end{itemize}

				\paragraph{Example}
					\enquote{The dog ate a cookie.}

					\begin{itemize}
						\item Textual notation:
							\begin{figure}[H]
								\centering

								\texttt{det(dog, The)} \\
								\texttt{nsubj(ate, dog)} \\
								\texttt{root(ROOT, ate)} \\
								\texttt{det(cookie, a)} \\
								\texttt{dobj(ate, cookie)}
							\end{figure}
						\item Line notation:
							\begin{figure}[H]
								\centering
								\begin{tikzpicture}[->]
									\node (the) {The};
									\node [right = of the] (dog) {Dog};
									\node [right = of dog] (ate) {ate};
									\node [right = of ate] (a) {a};
									\node [right = of a] (cookie) {cookie.};

									\draw (dog) to[bend right] node[above]{det} (the);
									\draw (ate) to[bend right] node[above]{nsubj} (dog);
									\draw (cookie) to[bend right] node[above]{det} (a);
									\draw (ate) to[bend right] node[below]{dobj} (cookie);
								\end{tikzpicture}
							\end{figure}
						\item Tree notation:
							\begin{figure}[H]
								\centering
								\begin{tikzpicture}[->, every node/.style = { minimum height = 0.8cm }]
									\node (ate) {ate};
									\node [below left = of ate] (dog) {Dog};
									\node [below = of dog] (the) {The};
									\node [below right = of ate] (cookie) {cookie.};
									\node [below = of cookie] (a) {a};

									\draw (dog) to node[left]{det} (the);
									\draw (ate) to node[left]{nsubj} (dog);
									\draw (cookie) to node[right]{det} (a);
									\draw (ate) to node[right]{dobj} (cookie);
								\end{tikzpicture}
							\end{figure}
					\end{itemize}
				% end
			% end

			\subsubsection{Software} % 13.59
				\begin{itemize}
					\item \textbf{Stanford Parser} (Java, PHP, Python, Ruby)
					\item \textbf{Berkeley Parser} (Java)
					\item \textbf{Mate Tools} (Java)
					\item \textbf{DKPro Core} (Java)
					\item \textbf{Natural Language Processing Toolkit (NLTK)} (Python)
				\end{itemize}
			% end
		% end
	% end

	\section{Semantic} % 13.60, 13.61
		\begin{itemize}
			\item \textit{Semantics} is the study of meaning.
			\item \textit{Lexical Semantics} is the study of the meaning of lexical terms (e.g. word).
			\item \textit{Structure Semantics} is the study of the relationships between the meaning of lexical items in a larger context (e.g. phrases, sentences, documents).
		\end{itemize}

		\subsection{Ambiguity} % -
			\begin{itemize}
				\item Lexical Ambiguity: \enquote{He hit the ball with a \ambiguity{bat}.}
					\begin{enumerate}
						\item \ambiguity{Bat} could refer to the animal or
						\item \ambiguity{Bat} could refer to a baseball racket.
					\end{enumerate}
				\item Syntactical Ambiguity: \enquote{If you love money problems show up.}
					\begin{enumerate}
						\item \ambiguity{If you love}, money problems show up.
						\item \ambiguity{If you love money}, problems show up.
						\item \ambiguity{If you love money problems}, show up.
					\end{enumerate}
				\item Syntactic and lexical ambiguity: \enquote{Time flies like an arrow.}
					\begin{enumerate}
						\item Time moves quickly.
						\item Measure the speed of flies the same way as the speed of an arrow.
						\item Measure the speed of flies like an arrow would.
						\item Measure the speed of flies that behave/look/\dots like an arrow.
						\item The insect type \enquote{time flies} enjoy a single arrow (like \enquote{fruit flies like a banana}).
						\item Each of the \enquote{time flies} individually enjoys a different arrow.
						\item A concrete object (e.g. Time magazine) travels through the air in an arrow-like manner.
						\item \dots
					\end{enumerate}
			\end{itemize}
		% end

		\subsection{Word Sense Disambiguation} % 13.68
			\begin{itemize}
				\item \textit{Word sense disambiguation} is about to remove the the ambiguity by putting the single words into the context of the sentence/text/\dots and using background information.
			\end{itemize}
		% end
	% end
% end

\chapter{Text Corpora, Lexical Resources and Knowledge Bases} % 14, (15)
\label{c:corpora}

\section{Text Corpora} % 14.3, 14.4, 14.5, 14.17
	\begin{itemize}
		\item A \textit{Text Corpus} is collection of text used to train or evaluate a system.
		\item Examples:
			\begin{itemize}
				\item Brown Corpus: 500 texts, 15 genres, \(\approx\) 1 mio. words
				\item Wall Street Journal Campus: news, \(\approx\) 30 mio. words
				\item British National Corpus: balanced among genres, \(\approx\) 100 mio. words
				\item WaCKy Corpora: large web corpora in multiple language
			\end{itemize}
		\item A \textit{Parallel Corpora} is a corpora with their documents translated into two or more languages.
			\begin{itemize}
				\item Ideally it is sentence-aligned.
				\item Used for machine translation or cross-lingual information retrieval.
				\item Examples:
					\begin{itemize}
						\item Canadian Hansard
						\item EuroParl
					\end{itemize}
			\end{itemize}
		\item A (good) corpus provides information about:
			\begin{itemize}
				\item real usage examples,
				\item a view on what is common and typical (e.g. count frequencies),
				\item a comprehensive and balanced view on language (if the corpus was constructed correspondingly),
				\item recent changes in a language (if the corpus is continuously updated) and
				\item a basis for reproducible experimental results.
			\end{itemize}
	\end{itemize}

	\subsection{Parameters of a Corpus} % 14.6
		\begin{itemize}
			\item Language (Monolingual, Multilingual, Parallel)
			\item Communication (Written, Spoken, Mix)
			\item Size
			\item Annotations
			\item Static \(\leftrightarrow\) Dynamic
			\item Genre/Text Type (news, novels, social media text, personal conversations, \dots)
			\item Domain/Topic (education, biology, information science, \dots)
			\item Time of Compilation/Creation Time
		\end{itemize}
	% end

	\subsection{Content of a Corpus} % -
		\subsubsection{Corpus Annotation} % 14.7, 14.8
			\begin{itemize}
				\item \textit{Corpus Annotations} are enrichments of a corpus with various types of information.
				\item Annotations can be done on different levels, e.g.:
					\begin{itemize}
						\item Word: part of speech, lemma, sense \\ These require segmentation of the document texts into parts.
						\item Phrase: named entities, multi-word expressions
						\item Sentence: sentence boundaries, syntactic tree
						\item Discourse: co-referential chains, discourse segments
					\end{itemize}
			\end{itemize}
		% end

		\subsubsection{Frequencies} % 14.18, 14.19, 14.21
			\begin{itemize}
				\item \textbf{Collocations:} Sequence of words that occur together usually often.
				\item \textbf{Distributional Hypothesis:} Word in the same context might have similar meanings.
			\end{itemize}
		% end
	% end

	\subsection{Distributional Hypothesis}
		\begin{itemize}
			\item Main idea: \begin{quote}
					"You shall know a word by the company it keeps" (Firth, 1957: p. 11)
				\end{quote}
			\item Words that occur in the same contexts have similar meanings
			\item She \ambiguity{adores} \ambiguity{green} paint.
				\begin{itemize}
					\item verbs expressing admiration: adores, loves, likes, \dots
					\item colors: green, blue, red, \dots
				\end{itemize}
			\item Word sense disambiguation
			\item Word space models: Compute word or text similarity
				\begin{itemize}
					\item \enquote{cab – van} is more similar than \enquote{cab – database}
				\end{itemize}
			\item It is important for:
				\begin{itemize}
					\item Document classification/clustering
					\item Information retrieval
					\item Question answering (find similar questions)
					\item Paraphrasing assistance
					\item Word embeddings and deep learning
				\end{itemize}
		\end{itemize}
		%end

		\subsection{Corpus Creation} % 14.12
			\begin{enumerate}
				\item Retrieve and store original documents.
				\item Convert these document to plain text.
				\item Segment the documents into chapters, sentences, phrases, words, \dots
				\item Create manual and/or automatic annotations.
				\item Store all data in a reusable format.
				\item Analyze and use the corpus.
			\end{enumerate}
			Important: Store all intermediate results and document the steps for reproducible results.

			\subsubsection{Storing Annotations} % 14.13
				There are two main ways to store annotations:
				\begin{enumerate}
					\item Inline Annotations
						\begin{itemize}
							\item The annotations are directly added to the text.
							\item This changes the format of the original.
						\end{itemize}
					\item Stand-off Annotations
						\begin{itemize}
							\item The annotations are stored in a separate file.
							\item This leaves the original file as is, but the annotation data has to be restored.
						\end{itemize}
				\end{enumerate}
			% end
		% end

		\subsection{Corpus Query Languages} % 14.23
			\begin{itemize}
				\item The standard operations in SQL are exact and substring matches.
				\item But with complex corpus queries, it should be possible to find things like:
					\begin{itemize}
						\item All words with 6 letters starting with A or K that end with a vowel.
						\item Sentences containing two words at any position.
						\item \dots
					\end{itemize}
				\item Possible solutions:
					\begin{itemize}
						\item SQL functions
						\item Pattern matching and regular expressions
						\item Corpus Query Processor (CQP) language
					\end{itemize}
			\end{itemize}
		% end

		\subsection{Example Corpora} % -
			\paragraph{Treebanks: Penn Treebank} % 14.10
				\begin{itemize}
					\item Mostly based on Wall Street Journal text.
					\item Annotations: POS, syntactic parse tree
				\end{itemize}
			% end

			\paragraph{Brown Corpus: POS-Tagged Text} % 7.9
				\begin{itemize}
					\item Inline POS-tags.
				\end{itemize}
			% end

			\paragraph{Corpora in Relational Databases} % 7.14
				\begin{itemize}
					\item Example: Leibniz Corpus Collection
				\end{itemize}
			% end

			\paragraph{XML Corpora: British National Corpus} % 14.15
				\begin{itemize}
					\item Stored in XML.
				\end{itemize}
			% end

			\paragraph{Getting Corpora} % 14.16
				\begin{itemize}
					\item Major organizations:
						\begin{itemize}
							\item Linguistic Data Consortium
							\item European Language Resources Association
						\end{itemize}
					\item Freely accessible corpora:
						\begin{itemize}
							\item Oxford Text Archive
							\item Electronic Text Archive
							\item Project Gutenberg
							\item Leibniz Corpora Collection
							\item NLTK Corpora
							\item Institut für Deutsche Sprache
						\end{itemize}
				\end{itemize}
			% end
		% end
	% end

	\section{Lexical Resources and Knowledge Bases} % 14.24, 14.25
		Types of lexical resources:
		\begin{itemize}
			\item Dictionaries
			\item Encyclopedias
			\item Thesauri
			\item Wordnets
			\item \dots
		\end{itemize}

		\subsection{Lexical Resources \( \leftrightarrow \) Corpora} % 14.26
			\begin{table}[H]
				\centering
				\begin{tabular}{l l}
					\textbf{Corpus}                           & \textbf{Lexical Resource}                        \\
					Collected from real-world text/speech.    & Derived from corpora (aggregated view).          \\
					Contains multiple occurrences of a lemma. & A lemma usually only occurs once.                \\
					Frequent phenomena occur more often.      & Rare and frequent phenomena are treated equally. \\
					Show how language is used                 & Describes how language is used.                  \\
					Provides typical context and frequencies. & Provide meta information (e.g. sense definition)
				\end{tabular}
			\end{table}
		% end

		\subsection{Meaning, Lexical Ambiguity, Synonymy} % 14.28, 14.29
			\begin{itemize}
				\item A single lexical entry may have multiple meanings.
				\item The meanings described in a dictionary are called \textit{word senses}.
				\item Example:
					\begin{itemize}
						\item The word \enquote{bat} could either refer
						\item to a racket or
						\item to an animal.
					\end{itemize}
				\item Vice versa, the same sense may have multiple associated words (synonyms).
			\end{itemize}
		% end

		\subsection{Relation Types} % 14.33
			\begin{table}[H]
				\centering
				\begin{tabular}{l|l|l|l}
					\textbf{Relation Type} & \textbf{Description}         & \textbf{Relations}   & \textbf{Example}                   \\ \hline
					synonymy               & same meaning                 & antonym of antonymy  & stack is synonym of pile           \\
					antonymy               & opposite meaning             & antonym of synonymy  & rich is antonym of poor            \\
					hypernymy              & broader meaning              & antonym of hyponymy  & vehicle is hypernym of car         \\
					hyponymy               & narrower meaning             & antonym of hypernym  & taxi is hyponym of car             \\
					co-hypernymy           & same hypernym                & hypernym, synonym    & cat and dog are co-hyponyms of pet \\
					troponymy              & \enquote{hyponymy for verbs} & related to hypernymy & (to) nap is troponym of (to) sleep \\
					holonymy               & X is the whole of Y          & antonym of meronymy  & car is holonym of door             \\
					meronymy               & X is a part of Y             & antonym of holonymy  & door is meornym of car             \\
					seeAlso                & related meaning              &                      & bread and baker are related
				\end{tabular}
			\end{table}
		% end

		\subsection{Wordnets} % 14.30, 14.31, 14.32
			\begin{itemize}
				\item Princeton WordNet
				\item GermaNet
				\item EuroWordNet
			\end{itemize}
		% end
	% end
% end

\chapter{Information Retrieval} % 16
	\section{Overview} % 16.3, 16.4
		\begin{itemize}
			\item \textit{Information Retrieval} is about retrieving information from unstructured data best matching a given query.
			\item Exemplary scenarios:
				\begin{itemize}
					\item Web search
					\item E-Mail search
					\item Search in knowledge base or wiki
					\item \dots
				\end{itemize}
		\end{itemize}

		\subsection{Basic Concepts} % 16.5
			\begin{itemize}
				\item \textit{Information Need}, also called \textit{intent}, is the state of a person requiring information for solving a problem.
				\item The system-interpretable information need is formulated as a \textit{Query}, e.g. the keywords entered into a search engine.
				\item The \textit{Relevance} is about how relevant a particular document is to a particular query. The task of IR is to retrieve the most relevant documents.
			\end{itemize}
		% end

		\subsection{IR Engine vs. DBMS} % 16.8
			\begin{itemize}
				\item The DBMS relies on structure in the data (tables, columns, \dots).
				\item An IR engine works with unstructured data like text.
				\item Thus, an IR engine supports more complex finding operations like \enquote{documents in which word1 is next to word2}.
				\item \lstinline|LIKE|-Queries in DBMS require linear searches on the text and full table scans \(\implies\) inefficient.
			\end{itemize}
		% end

		\subsection{Core Challenges in IR} % 16.9
			\begin{itemize}
				\item \textbf{Number of result:} There are millions of documents in the web, what are the relevant ones?
				\item \textbf{Relevance:} Some results may be better than others, how to separate them?
				\item \textbf{Intent:} The user may not use an ideal query for their information need, how to find what the user wants rather than what the user says he wants?
				\item \textbf{Lexical gap:} Searching for \enquote{get rid of mice} should lead to documents about mouse traps.
				\item \textbf{Ambiguity:} Mouse may be an animal or an input device, how to separate?
			\end{itemize}
		% end

		\subsection{IR Activities} % 16.10
			\begin{itemize}
				\item \textit{Indexing:} Create a simple document representation to enhance search.
				\item \textit{Searching:} Interpret the query and return matching documents, sorted by relevance, ranked by results, improved by user feedback, \dots.
			\end{itemize}
		% end
	% end

	\section{Boolean Retrieval} % 16.12, 16.13
		\begin{itemize}
			\item \textit{Boolean Retrieval} is the most simple retrieval model.
			\item One document is considered to be a \textit{set of words} with no duplicates.
			\item Searching for documents be like:
				\begin{itemize}
					\item contains a word,
					\item does not contain a word,
					\item contains word1 and word2,
					\item contains word1 or word2
				\end{itemize}
		\end{itemize}

		\subsection{Term-Document Matrix} % 16.14
			Whether a word is contained in a document can be represented as a 1, not containing as a 0. This leads to the following matrix (as an example), the so-called \textit{Term-Document Matrix}:
			\begin{table}[H]
				\centering
				\begin{tabular}{|l|c|c|c|c|c|c|c|}
					\hline
					\textbf{Term} \(t\) & \makecell{Webshop \\ deadfall \\ traps} & \makecell{Wikipedia: \\ mouse- \\ traps} & \makecell{Webshop \\ live- \\ capture \\ traps 1} & \makecell{Wikipedia: \\ traps} & \makecell{tips to \\ get rid of \\ rodents} & \makecell{Webshop \\ live- \\ capture \\ traps 2} & \makecell{bear \\ hunting \\ overview} \\ \hline
					\texttt{mouse}      & 1                                       & 1                                        & 1                                                 & \textcolor{irl}{0}             & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     \\ \hline
					\texttt{trap}       & 1                                       & 1                                        & 1                                                 & 1                              & \textcolor{irl}{0}                          & 1                                                 & \textcolor{irl}{0}                     \\ \hline
					\texttt{not}        & 1                                       & \textcolor{irl}{0}                       & 1                                                 & \textcolor{irl}{0}             & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     \\ \hline
					\texttt{hurt}       & \textcolor{irl}{0}                      & 1                                        & 1                                                 & \textcolor{irl}{0}             & 1                                           & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     \\ \hline
					\texttt{dead}       & 1                                       & \textcolor{irl}{0}                       & \textcolor{irl}{0}                                & 1                              & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     \\ \hline
					\texttt{alive}      & \textcolor{irl}{0}                      & \textcolor{irl}{0}                       & \textcolor{irl}{0}                                & 1                              & 1                                           & 1                                                 & \textcolor{irl}{0}                     \\ \hline
					\texttt{bear}       & \textcolor{irl}{0}                      & \textcolor{irl}{0}                       & \textcolor{irl}{0}                                & \textcolor{irl}{0}             & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & 1                                      \\ \hline
					\texttt{rodent}     & \textcolor{irl}{0}                      & 1                                        & \textcolor{irl}{0}                                & \textcolor{irl}{0}             & 1                                           & 1                                                 & \textcolor{irl}{0}                     \\ \hline
				\end{tabular}
			\end{table}
			\begin{itemize}
				\item One column represents one document and one row represents one term.
				\item As said above, a 1 means the term is in the document, a 0 means the term is not.
				\item When searching for a term, say \( (\text{mouse} \lor \text{rodent}) \land \lnot\text{hurt} \), the searching can be processed using bit-wise logic:
					\begin{align*}
						       & \quad (\text{mouse} \lor \text{rodent}) \land \lnot\text{hurt}                 \\
						\simeq & \quad (\texttt{1110000} \lor \texttt{0100110}) \land \lnot\texttt{0110100}     \\
						=      & \quad \texttt{1110110} \land \texttt{1001011}                                  \\
						=      & \quad \texttt{1000010}                                                         \\
						\simeq & \quad \{ \text{Webshop deadfall traps}, \text{Webshop live-capture traps 2} \}
					\end{align*}
				\item The result bit pattern, \texttt{1000010}, refers to the documents to select: \enquote{Webshop deadfall traps} and \enquote{Webshop live-capture traps 2}.
			\end{itemize}

			\subsubsection{Scaling, Inverted Matrix} % 16.16, 16.17, 16.18, 16.19, 16.20
				\begin{itemize}
					\item Saving the matrix as described above would lead to high memory usages to save lots of 0s.
					\item There must be a better way to save the data.
					\item Idea: Just save the 1s.
					\item This can be done using an \textit{Inverted Index}:
						\begin{itemize}
							\item Each document is assigned a number (say from d1 to d7 for the example above).
							\item Then, each term is assigned a set of document numbers the term appears in.
							\item Using this technique, one the appearances of a word are saved rather than saving a bunch of \enquote{does not appear in}, \enquote{does not appear in}, \enquote{does not appear in}, \dots.
						\end{itemize}
				\end{itemize}

				\begin{table}[H]
					\centering
					\begin{tabular}{|l|c|c|c|c|c|c|c|}
						\cline{2-8}
						\multicolumn{1}{c|}{} & \makecell{Webshop \\ deadfall \\ traps} & \makecell{Wikipedia: \\ mouse- \\ traps} & \makecell{Webshop \\ live- \\ capture \\ traps 1} & \makecell{Wikipedia: \\ traps} & \makecell{tips to \\ get rid of \\ rodents} & \makecell{Webshop \\ live- \\ capture \\ traps 2} & \makecell{bear \\ hunting \\ overview} \\ \cline{2-8}
						\multicolumn{1}{c|}{} & d1                                      & d2                                       & d3                                                & d4                             & d5                                          & d6                                                & d7                                     \\ \cline{2-8}
						\multicolumn{8}{c}{}                                                                                                                                                                                                                                                                                                                       \\ \cline{1-4}
						\texttt{mouse}        & d1                                      & d2                                       & d3                                                & \multicolumn{4}{c}{}                                                                                                                                                      \\ \cline{1-6}
						\texttt{trap}         & d1                                      & d2                                       & d3                                                & d4                             & d6                                          & \multicolumn{2}{c}{}                                                                       \\ \cline{1-6}
						\texttt{not}          & d1                                      & d3                                       & \multicolumn{5}{c}{}                                                                                                                                                                                                          \\ \cline{1-4}
						\texttt{hurt}         & d2                                      & d3                                       & d5                                                & \multicolumn{4}{c}{}                                                                                                                                                      \\ \cline{1-4}
						\texttt{dead}         & d1                                      & d4                                       & \multicolumn{5}{c}{}                                                                                                                                                                                                          \\ \cline{1-4}
						\texttt{alive}        & d4                                      & d5                                       & d6                                                & \multicolumn{4}{c}{}                                                                                                                                                      \\ \cline{1-4}
						\texttt{bear}         & d1                                      & \multicolumn{6}{c}{}                                                                                                                                                                                                                                                     \\ \cline{1-4}
						\texttt{rodent}       & d2                                      & d5                                       & d6                                                & \multicolumn{4}{c}{}                                                                                                                                                      \\ \cline{1-4}
					\end{tabular}
				\end{table}
			% end
		% end
	% end

	\section{Vector Space Model} % 16.21
		\subsection{Boolean Search Issues} % 16.22
			\begin{enumerate}
				\item \textbf{Syntax Needed}
					\begin{itemize}
						\item The user has to write Boolean expressions.
						\item This is nearly impossible for the average user and time-consuming for the expert user.
						\item \textbf{Solution:} use keyword-bases search instead (e.g. \( \text{mouse trap} \simeq \text{mouse} \land \text{trap} \)).
					\end{itemize}
				\item \textbf{\enquote{Feast or Famine}}
					\begin{itemize}
						\item Boolean queries often give either too few (\( \approx 0 \)) or too many (\( \gg 1000 \)) results.
						\item Neither of these is useful.
						\item \textbf{Solution:} Ranked retrieval.
					\end{itemize}
			\end{enumerate}
		% end

		\subsection{Ranked Retrieval} % 16.23
			\begin{itemize}
				\item In the Boolean retrieval, a term was either in a document or not.
				\item But a document containing one word multiple times may be more relevant that a document containing the term a single time.
				\item Idea: Sort (rank) the results by relevance.
				\item Often, the best 10 results are the most relevant. Others can be discarded.
				\item This solves the \enquote{feast or famine}-problem.
			\end{itemize}

			\subsubsection{Time-Document Matrix Weights} % 16.24, 16.25
				\begin{itemize}
					\item Instead of weighing the matrix components as 1 or 0, each field can be assigned the \textit{Term Frequency}, the occurrence count of a word.
					\item That way, the matrix is weighted and can distinguish between not-so-relevant and relevant results.
				\end{itemize}
				\begin{table}[H]
					\centering
					\begin{tabular}{|l|c|c|c|c|c|c|c|}
						\hline
						\textbf{Term} \(t\) & \makecell{Webshop \\ deadfall \\ traps} & \makecell{Wikipedia: \\ mouse- \\ traps} & \makecell{Webshop \\ live- \\ capture \\ traps 1} & \makecell{Wikipedia: \\ traps} & \makecell{tips to \\ get rid of \\ rodents} & \makecell{Webshop \\ live- \\ capture \\ traps 2} & \makecell{bear \\ hunting \\ overview} \\ \hline
						\texttt{mouse}      & 12                                      & 53                                       & 3                                                 & \textcolor{irl}{0}             & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     \\ \hline
						\texttt{trap}       & 5                                       & 11                                       & 34                                                & 10                             & \textcolor{irl}{0}                          & 8                                                 & \textcolor{irl}{0}                     \\ \hline
						\texttt{not}        & 231                                     & \textcolor{irl}{0}                       & 53                                                & \textcolor{irl}{0}             & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     \\ \hline
						\texttt{hurt}       & \textcolor{irl}{0}                      & 1                                        & 22                                                & \textcolor{irl}{0}             & 2                                           & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     \\ \hline
						\texttt{dead}       & 50                                      & \textcolor{irl}{0}                       & \textcolor{irl}{0}                                & 3                              & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     \\ \hline
						\texttt{alive}      & \textcolor{irl}{0}                      & \textcolor{irl}{0}                       & \textcolor{irl}{0}                                & 5                              & 7                                           & 3                                                 & \textcolor{irl}{0}                     \\ \hline
						\texttt{bear}       & \textcolor{irl}{0}                      & \textcolor{irl}{0}                       & \textcolor{irl}{0}                                & \textcolor{irl}{0}             & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & 32                                     \\ \hline
						\texttt{rodent}     & \textcolor{irl}{0}                      & 45                                       & \textcolor{irl}{0}                                & \textcolor{irl}{0}             & 3                                           & 5                                                 & \textcolor{irl}{0}                     \\ \hline
					\end{tabular}
				\end{table}
			% end
		% end

		\subsection{Set of Words, Bag of Words} % 16.26
			\begin{itemize}
				\item Set of Words
					\begin{itemize}
						\item Disregards word order, grammar, meaning, \dots
						\item A document either contains a term or not.
						\item Each term is assumed to occur only once or never.
					\end{itemize}
				\item Bag of Words
					\begin{itemize}
						\item Disregards word order, grammar, meaning, \dots
						\item A token may occur multiple times in a document.
						\item The term frequency (TF) function represents the occurrence counts.
					\end{itemize}
			\end{itemize}
		% end

		\subsection{Vector Space Model (VSM)} % 16.27, 16.28
			\begin{itemize}
				\item Each document in the TD-matrix can be represented as an \(n\)-dimensional vector, where \(n\) is the number of terms.
				\item This puts the TD-matrix into a vector space which then allows to apply linear algebra operations.
			\end{itemize}

			\paragraph{Example}
				\textit{In this example, the dimension of the VCM is reduced to 2 to ease the visualization, a 8-dimensional vector space is kinda complicated to visualize.}

				Given the following TD-matrix (reduced to 2 dimensions as explained):
				\begin{table}[H]
					\centering
					\begin{tabular}{|l|c|c|c|c|c|c|c|}
						\hline
						\textbf{Term} \(t\) & \makecell{tips to \\ get rid of \\ rodents \\ (D1)} & \makecell{Webshop \\ live- \\ capture \\ traps 2 \\ (D2)} \\ \hline
						\texttt{alive}      & 7                                                   & 3                                                         \\ \hline
						\texttt{rodent}     & 3                                                   & 5                                                         \\ \hline
					\end{tabular}
				\end{table}
				So, the documents D1 and D2 can be represented using vectors:
				\begin{equation*}
					\text{D1} =
					\begin{bmatrix}
						7 \\
						3
					\end{bmatrix},
					\quad\quad
					\text{D2} =
					\begin{bmatrix}
						3 \\
						5
					\end{bmatrix}
				\end{equation*}
				In a two-dimensional vector space, this gives the following graph:
				\begin{figure}[H]
					\centering
					\begin{tikzpicture}
						\begin{axis}[
								xlabel = \texttt{alive},
								ylabel = \texttt{rodent},
								xmin = 0,
								xmax = 8,
								ymin = 0,
								ymax = 8
							]
							\addplot [->] coordinates { (0, 0) (7, 3) } node[above]{D1};
							\addplot [->] coordinates { (0, 0) (3, 5) } node[above]{D2};
						\end{axis}
					\end{tikzpicture}
				\end{figure}
			% end
		% end

		\subsection{Search the VSM} % 16.29
			Given the above vector space, it is possible to trace out a query \(Q\) in the vector space:
			\begin{figure}[H]
				\centering
				\begin{tikzpicture}
					\begin{axis}[
							xlabel = \texttt{alive},
							ylabel = \texttt{rodent},
							xmin = 0,
							xmax = 8,
							ymin = 0,
							ymax = 8
						]
						\addplot [->] coordinates { (0, 0) (7, 3) } node[above]{D1};
						\addplot [->] coordinates { (0, 0) (3, 5) } node[above]{D2};
						\addplot [->, TUDa-10b] coordinates { (0, 0) (6, 7) } node[above]{Q};
					\end{axis}
				\end{tikzpicture}
			\end{figure}

			\subsubsection{Vector Similarity} % 3.30, 3.31, 3.32, 3.33
				\begin{itemize}
					\item To find results in the VSM, the similarity between the vectors has to be calculated.
					\item The first approach might be to use the \textbf{Euclidean Similarity}, which is to calculate the distance between the query vector and every other vector:
						\begin{equation*}
							\text{Similarity}(D, Q) = \abs{Q - D}
						\end{equation*}
						Problem: The distance differs depending on how often a keyword is entered into the query.
					\item The much better approach is not measure the angle between the query vector and every other vector:
						\begin{equation*}
							\text{Similarity}(D, Q) = \frac{\langle Q \,\vert\, D \rangle}{\abs{Q} \cdot \abs{D}}
						\end{equation*}
					\item Example:
						\begin{itemize}
							\item \(q = (0;5;0;1;0)\)
							\item \(v = (0;2;3;2;1)\)
						\end{itemize}
						\begin{equation*}
							\text{sim}(q,v) = \frac{0 \cdot 0 + 5 \cdot 2 + 0 \cdot 3 + 1 \cdot 2 + 0 \cdot 1}{\sqrt{0^2 + 5^2 + 0^2 + 1^2 + 0^2} \cdot \sqrt{0^2 + 2^2 + 3^2 +2^2 + 1^2}}
							= \frac{12}{\sqrt{26} \cdot \sqrt{18}} \approx 0.55
						\end{equation*}

				\end{itemize}
			% end
		% end

		\subsection{Vector Weights} % -
			\begin{itemize}
				\item Let \( v = (w_{t_1}, \cdots, w_{t_n}) \) be the vector for the document \( d \) with terms \( t_1 \) to \( t_n \).
				\item Let \( \text{tf}_d(t) \) be the occurrence count of \(t\) in \(d\), the \textit{Term Frequency}.
			\end{itemize}

			\paragraph{Binary} % 16.34
				\begin{equation*}
					w_t =
					\begin{cases}
						1 & t \in d          \\
						0 & \text{otherwise}
					\end{cases}
				\end{equation*}

				\begin{itemize}
					\item Discussion: Isn't there a relevance difference between documents with one occurrence and a document with thousand occurrences?
				\end{itemize}
			% end

			\paragraph{Term Frequencies} % 16.35
				\begin{equation*}
					w_t =
					\begin{cases}
						\text{tf}_d(t) & t \in d          \\
						0              & \text{otherwise}
					\end{cases}
				\end{equation*}

				\begin{itemize}
					\item Discussion: Is a document containing the search term 1000 times really 100 times more relevant than a document containing the search term 10 times?
				\end{itemize}
			% end

			\paragraph{Normalized Term Frequencies} % 16.36
				\begin{equation*}
					w_t =
					\begin{cases}
						\log_{10}(\text{tf}_d(t)) + 1 & t \in d          \\
						0                             & \text{otherwise}
					\end{cases}
				\end{equation*}

				\begin{itemize}
					\item Discussion: Determiners occur very often, but are not really relevant. Words occurring rarely over a set of document would be useful.
					\item Example: the, a and am appear very often and are probably not as important as paint, colour, mouse, \dots
				\end{itemize}
			% end

			\paragraph{Document Frequency} % 16.37
				Let \( \text{df}(t) \) be the count of documents containing the term \(t\), the \textit{Document Frequency}.
				\begin{equation*}
					w_t =
					\begin{cases}
						f(\log_{10}(\text{tf}_d(t)) + 1, \text{df}(t)) & t \in d          \\
						0                                              & \text{otherwise}
					\end{cases}
				\end{equation*}
				with some function \( f(\cdot, \cdot) \).

				\begin{itemize}
					\item Discussion; TF should be maximized, DF should be minimized \(\implies\) hard to perform on a single output number.
				\end{itemize}
			% end

			\subsubsection{Inverse Document Frequency} % 16.38
				Let \( \text{idf}(t) \coloneqq \log_{10}\Big(\frac{\abs{D}}{\text{df(t)}}\Big) \) be the \textit{Inverse Document Frequency} with the document set \(D\).
				\begin{equation*}
					w_t =
					\begin{cases}
						f(\log_{10}(\text{tf}_d(t)) + 1, \text{idf}(t)) & t \in d          \\
						0                                               & \text{otherwise}
					\end{cases}
				\end{equation*}
				with some function \( f(\cdot, \cdot) \).
			% end

			\subsubsection{Concrete Vector Weights: TF.IDF} % 16.40
				\begin{equation*}
					w_t =
					\begin{cases}
						(\log_{10}(\text{tf}_d(t)) + 1) \cdot \text{idf}(t) & t \in d          \\
						0                                                   & \text{otherwise}
					\end{cases}
				\end{equation*}

				Of course, other normalization strategies are also possible, like:
				\begin{equation*}
					w_t =
					\begin{cases}
						\text{tf}_d(t) \cdot \text{idf}(t) & t \in d          \\
						0                                  & \text{otherwise}
					\end{cases}
				\end{equation*}
			% end
		% end

		\subsection{VSM Retrieval: Example} % 16.43, 16.44, 16.45, 16.46, 16.47
			\begin{table}[H]
				\centering
				\begin{tabular}{|l|c|c|c|c|c|c|c||c|}
					\hline
					\textbf{Term} \(t\)    & \makecell{Webshop \\ deadfall \\ traps} & \makecell{Wikipedia: \\ mouse- \\ traps} & \makecell{Webshop \\ live- \\ capture \\ traps 1} & \makecell{Wiki- \\ pedia: \\ traps} & \makecell{tips to \\ get rid of \\ rodents} & \makecell{Webshop \\ live- \\ capture \\ traps 2} & \makecell{bear \\ hunting \\ overview} & \makecell{Query \\ Q} \\ \hline
					\texttt{mouse}         & 12                                      & 53                                       & 3                                                 & \textcolor{irl}{0}                  & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     & 1                     \\ \hline
					\texttt{trap}          & 5                                       & 11                                       & 34                                                & 10                                  & \textcolor{irl}{0}                          & 8                                                 & \textcolor{irl}{0}                     & 1                     \\ \hline
					\texttt{not}           & 231                                     & \textcolor{irl}{0}                       & 53                                                & \textcolor{irl}{0}                  & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     & 1                     \\ \hline
					\texttt{hurt}          & \textcolor{irl}{0}                      & 1                                        & 22                                                & \textcolor{irl}{0}                  & 2                                           & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     & 1                     \\ \hline
					\texttt{dead}          & 50                                      & \textcolor{irl}{0}                       & \textcolor{irl}{0}                                & 3                                   & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & \textcolor{irl}{0}                     & 0                     \\ \hline
					\texttt{alive}         & \textcolor{irl}{0}                      & \textcolor{irl}{0}                       & \textcolor{irl}{0}                                & 5                                   & 7                                           & 3                                                 & \textcolor{irl}{0}                     & 0                     \\ \hline
					\texttt{bear}          & \textcolor{irl}{0}                      & \textcolor{irl}{0}                       & \textcolor{irl}{0}                                & \textcolor{irl}{0}                  & \textcolor{irl}{0}                          & \textcolor{irl}{0}                                & 32                                     & 0                     \\ \hline
					\texttt{rodent}        & \textcolor{irl}{0}                      & 45                                       & \textcolor{irl}{0}                                & \textcolor{irl}{0}                  & 3                                           & 5                                                 & \textcolor{irl}{0}                     & 0                     \\ \hline\hline
					\( \abs{d} \)          & 237                                     & 70                                       & 67                                                & 12                                  & 8                                           & 9                                                 & 6                                      & 2                     \\ \hline
					\( \text{sim}(D, Q) \) & 0.52                                    & 0.46                                     & 0.84                                              & 0.42                                & 0.13                                        & 0.44                                              & 0                                      & \multicolumn{1}{c}{}  \\ \cline{1-8}
				\end{tabular}
			\end{table}
		% end
	% end

	\section{Information Retrieval Evaluation} % 16.49, 16.50, 16.51, 16.52, 16.53, 16.54
		\begin{itemize}
			\item The evaluation of a retrieval system is extremely important to check how good the retrieval system really is.
			\item The basic measurements are:
				\begin{itemize}
					\item \textit{Precision} - The fraction of the retrieved documents that are relevant to the user's information need.
						\begin{equation*}
							P = \frac{\abs{\text{Retrieved} \cap \text{Relevant}}}{\abs{\text{Retrieved}}} = \frac{\abs{\text{True Positives}}}{\abs{\text{True Positives}} + \abs{\text{False Positives}}}
						\end{equation*}
					\item \textit{Recall} - The fraction of the relevant documents if the collection that are retrieved.
						\begin{equation*}
							R = \frac{\abs{\text{Retrieved} \cap \text{Relevant}}}{\abs{\text{Relevant}}} = \frac{\abs{\text{True Positives}}}{\abs{\text{True Positives}} + \abs{\text{False Negatives}}}
						\end{equation*}
				\end{itemize}
			\item Confusion Matrix
				\begin{table}[H]
					\centering
					\begin{tabular}{r | c | c | c}
						              & Relevant & Irrelevant & \( \Sigma \) \\ \hline
						Retrieved     & TP = 2   & FP = 1     & 3            \\ \hline
						Not Retrieved & FN = 3   & TN = ??    &              \\ \hline
						\(\Sigma\)    & 5        &            &
					\end{tabular}
				\end{table}
		\end{itemize}

		\subsection{\( F _ 1 \) Score} % 16.55
			The \(F_1\)-score is the weighted average of precision and recall:
			\begin{equation*}
				F_1 = \frac{2PR}{P + R} \tag{Harmonic Mean of \(P\) and \(R\)}
			\end{equation*}

			\paragraph{Generalization: \( F _ \beta \) Score}
				\begin{equation*}
					F _ \beta = \frac{(1 + \beta^2) P R}{\beta^2 P + R}
				\end{equation*}
			% end
		% end

		\subsection{Cutoff and Precision at Rank} % 16.56
			\begin{equation*}
				\text{P@R} = \frac{\text{\#Relevant Documents before } R}{R} \tag{Precision at Rank}
			\end{equation*}
		% end
	% end
% end

\chapter{Information Extraction and Classification} % 17, (18)
\section{Information Extraction (IE)} % 17.3
	\begin{description}
		\item[Given] A document collection.
		\item[Goal] Extract structured knowledge, entities, facts, \dots.
	\end{description}

	\subsection{Information Retrieval vs. Information Extraction} % 17.5, 17.6
		\begin{itemize}
			\item \textit{Information Retrieval} finds documents that are relevant to a query.
				\begin{itemize}
					\item Output: List of relevant documents.
					\item A lot less difficult than IE, as \enquote{only} documents have to be found.
					\item Domain-independent.
					\item Query types are usually unconstrained (can contain any keyword).
					\item Faster.
					\item Less effective as the user wants answers, not documents.
				\end{itemize}
			\item \textit{Information Extraction} extracts structured information from an unstructured document.
				\begin{itemize}
					\item Output: Set of structured facts extracted from documents.
					\item Much more difficult than IR (has to do IR first and then extract facts).
					\item Often domain-dependent.
					\item Pre-defined query types (e.g. SQL).
					\item Slower.
					\item More effective as the user wants answers and gets answers.
				\end{itemize}
		\end{itemize}
	% end
% end

\section{Entity Recognition} % -
\subsection{Entity Types} % 17.7
	Commonly used entity types:
	\begin{table}[H]
		\centering
		\begin{tabular}{l l}
			\textbf{Type} & \textbf{Examples}             \\
			ORGANIZATION  & TU Darmstadt, TU Dresden      \\
			PERSON        & Angela Merkel, Goethe         \\
			LOCATION      & Darmstadt, Rhein, Luisenplatz \\
			DATE          & 10.09.2018                    \\
			TIME          & 10:00                         \\
			MONEY         & 250 Euros                     \\
			PERCENT       & 43\%                          \\
			FACILITY      & London Bridge, Karo5          \\
			\dots         & \dots
		\end{tabular}
	\end{table}
	The definition of the concrete used entity types highly depends on the domain and on the task.
% end

\subsection{Challenges} % 17.8, 17.9
	\begin{itemize}
		\item Entity vs. Non-Entity \\ Example: Mobile Phone vs. Mobile, Alabama
		\item Coverage Issues \\ Example: It is impossible to create a list of all persons, locations, \dots.
		\item Variation \\ Example: John Smith vs. Mr. Smith, John vs. Mr. J. Smith
		\item Ambiguity \\ Example: Darmstadt (German vs. US city)
		\item Time Dependency \\ Example: The president of the TU Darmstadt (Prömel, Wörner, \dots).
		\item Multi-word Expressions; The boundaries are often not clear. \\ Example: Carlo und Karin Giersch-Stiftung an der TU Darmstadt
		\item Metonymy
			\begin{itemize}
				\item A figure of speech in which an entity is not called by its name but by the name of any property intimately associated with it.
				\item Examples:
					\begin{itemize}
						\item Darmstadt won by a penalty goal in the last minute of the game. \\ (Darmstadt does not refer to the city, but to the SV Darmstadt 98.)
						\item She only reads Goethe and Schiller. \\ (Refers to books of Goethe and Schiller, not their personalities.)
					\end{itemize}
			\end{itemize}
	\end{itemize}
% end

\subsection{Approaches} % -
	\subsubsection{List Lookup} % 17.10
		\begin{itemize}
			\item Recognize only entities that are stored in a list.
			\item For locations, these lists are called \textit{gazetteers}.
			\item \textbf{Advantages}
				\begin{itemize}
					\item Simple
					\item Fast
					\item Easy to adapt to a different domain
				\end{itemize}
			\item \textbf{Disadvantages}
				\begin{itemize}
					\item Lists have to be collected and maintained
					\item Cannot deal with name variants and abbreviations
					\item Cannot resolve ambiguity
				\end{itemize}
		\end{itemize}
	% end

	\subsubsection{Rule-based Methods} % 17.11, 17.12
		\begin{itemize}
			\item Most often, the rules are regular expressions.
			\item But: Extremely Labor-intensive.
				\begin{itemize}
					\item It is easy to get a fairly good performance (e.g. 50\% correct).
					\item But it is incredible hard to get a good performance (e.g. > 70\% correct).
					\item It is very expensive to maintain and to adapt to new domains, tasks and languages.
				\end{itemize}
		\end{itemize}
	% end
% end
\subsection{Next Steps After Information Extraction} % 17.13
	\begin{itemize}
		\item After we extracted all these facts, what shall we do with this information?
		\item We save it in a knowledge base
	\end{itemize}

	\subsubsection{Knowledge Bases}
		\begin{itemize}
			\item A knowledge base is a special kind of database for knowledge management. A knowledge base provides a means for information to be collected, organized, shared, searched and utilized.
			\item Collection of facts, which can be stored as SPO Triples (Subject, Predicate, Object)
			\item Example: "Leonard Nimoy was an actor who played the character Spock in the science-fiction movie Star Trek"
				\begin{table}[H]
					\centering
					\begin{tabular}{r | c | l}
						\textbf{Subject} & \textbf{Predicate} & \textbf{Object} \\ \hline
						(LeonardNimoy,   & profession,        & Actor)          \\
						(LeonardNimoy,   & starredIn,         & StarTrek)       \\
						(LeonardNimoy,   & played,            & Spock)          \\
						(Spock           & characterIn,       & StarTrek)       \\
						(StarTrek        & genre,             & ScienceFiction) \\
					\end{tabular}
				\end{table}
			\item SPO Triples can be combined to form a graph
				\begin{description}
					\item[Nodes] Entities (all subjects and objects)
					\item[Directed edges] predicates
				\end{description}
			\item This graph is called a \textbf{Knowledge Graph (KG)}
		\end{itemize}
	% end
	\subsubsection{Knowledge Base Construction Methods}
		\begin{itemize}
			\item \textbf{Curated approaches}
				\begin{itemize}
					\item Triples are created manually by a closed group of experts
					\item (+) High quality
					\item (-) Low scalability
				\end{itemize}
			\item \textbf{Collaborative approaches}
				\begin{itemize}
					\item Triples are created manially by an open group of volunteers
					\item Examples: Freebase, Wikipedia, Wikidata
					\item (+) Better scalability
					\item (-) Still limited
				\end{itemize}
			\item \textbf{Automated semi-structured approaches}
				\begin{itemize}
					\item Triples are extracted automatically from semi-structured text
						\begin{itemize}
							\item Infoboxes in Wikipedia
							\item hand-crafted rules, learned rules or regular expressions
						\end{itemize}
					\item Examples: YAGO, DBPedia
					\item (+) Large knowledge graphs
					\item (-) Still cover only a small fraction of the Web
				\end{itemize}
			\item \textbf{Automated unstructured approaches}
				\begin{itemize}
					\item Triples are extracted automatically from unstructured text
					\item Machine learning and natural language processing (NLP) techniques
					\item Examples: NELL, Knowledge Vault
					\item (+) huge knowledge graphs: "read the web"
				\end{itemize}
		\end{itemize}
		%end
	% end
% end

\section{Supervised vs. Probabilistic Machine Learning} % 17.14, 17.15, 17.16
	\begin{itemize}
		\item Supervised Machine Learning
			\begin{itemize}
				\item Core Idea: Create a dataset and let the machine learn rules or statistical models to label unseen data.
			\end{itemize}
		\item Corpus-based Probabilistic Methods
			\begin{itemize}
				\item Core Idea: Estimate the probability for certain language structures based in large corpora.
			\end{itemize}
	\end{itemize}

	\subsection{Classification}
		\begin{itemize}
			\item \textbf{Classification} is the task if choosing the correct \textbf{class label} for a given input (=instance) based in its features
			\item Examples:
				\begin{itemize}
					\item Email spam classification
					\item Categorizing news articles by topic
				\end{itemize}
			\item \textbf{Classification variants}
				\begin{itemize}
					\item binary (2 classes) vs multi-class classification (\(>\)2 classes)
					\item multi-class problem can be decomposed using binary classifiers
					\item single-label vs. multi-label classification, each instance may be assigned one vs. multiple class labels
					\item sequence classification, a sequence of instances are jointly classified
				\end{itemize}
		\end{itemize}
	% end

	\subsection{General (Supervised) ML Workflow}
		\begin{enumerate}
			\item Obtain training, development, test data
			\item Represent the input (e.g., using features)
			\item Select an algorithm and train the model
			\item Evaluate the results; perform the task
		\end{enumerate}

		\subsubsection{Split the Data}
			\begin{itemize}
				\item If possible: use separate datasets for development, testing and evaluation
				\item If not: divide one large dataset in three parts
			\end{itemize}
			\begin{description}
				\item[Training Set] Trains the model
				\item[Test Set] Analyze errors, select features and optimize parameters on it
				\item[Evaluation Set] Test on held-out data and evaluate how well the algorithm works, dont optimize on it
			\end{description}
		% end
	% end
% end
