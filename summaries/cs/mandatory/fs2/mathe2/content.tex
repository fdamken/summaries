\todo{Vollständigkeitsprüfung}



\chapter{Allgemein}
	\section{Definitionen}
		\begin{description}
			\item[Skalarprodukt] Sei $ V $ eim $ \mathbb{R}\text{-Vektorraum} $. Eine Abbildung $ (\cdot \vert \cdot) : V \times V \rightarrow \mathbb{R} $ heißt Skalarprodukt gdw.
				\begin{itemize}
					\item $ \forall x \in V : (x \vert x) \geq 0 \land ((x \vert x) = 0 \iff x = 0) $ (Definitheit)
					\item $ \forall x, y \in V : (x \vert y) = (y \vert x) $ (Symmetrie)
					\item $ \forall x, y, z \in V : \forall \alpha, \beta \in \mathbb{R} : (\alpha x + \beta y \vert z) = \alpha (x \vert z) + \beta (y \vert z) $ (Linearität im ersten Argument)
				\end{itemize}
		\end{description}
	% end

	\section{Sätze}
		\subsection{Eulersche Formel}
			Es gilt für alle $ \varphi \in \mathbb{C} $ \[ e ^ { \varphi i } = \text{cos}(\varphi) + i \cdot \text{sin}(\varphi) \]
		% end

		\subsection{Eulersche Potenz}
			Es gilt für alle $ a, b \in \mathbb{R} $ \[ a ^ b = e ^ { \text{ln}(a) \cdot b } \]
		% end
	% end
% end

\chapter{Folgen}
	Eine Folge $ (a _ n) $ in $ \mathbb{K} $ ist, naiv gesprochen, eine Funktion $ a : \mathbb{N} \rightarrow \mathbb{K} $, welche die natürlichen Zahlen auf einen Zahlenraum $ \mathbb{K} $ abbildet.

	\section{Definitionen}
		\begin{description}
			\item[Konvergenz] Eine Folge $ (a _ n) $ konvergiert gegen $ a $ gdw. $ \forall \varepsilon > 0 : \exists n _ 0 \in \mathbb{N} : \forall n \geq n _ 0 : \lvert a _ n - a \rvert < \varepsilon $. Dieses $ a $ wird \textit{Grenzwert} oder \textit{Limes} von $ (a _ n) $ genannt ($ \liminfty a _ n = a $).
			\item[Cauchy-Folge] Eine Folge $ (a _ n) $ in $ \mathbb{K} $ heißt Cauchy-Folge gdw. \[ \forall \varepsilon > 0 : \exists n _ 0 \in \mathbb{N} : \forall n, m \geq n _ 0 : \abs{a _ n - a _ m} < \varepsilon \] Satz: Jede konvergente Folge in $ \mathbb{K} $ ist eine Cauchy-Folge.
			\item[Vollständig normierter Raum] Ein Raum $ \mathbb{K} $ wird als \textit{vollständig normiert} bezeichnet, wenn jede Cauchy-Folge in $ \mathbb{K} $ konvergiert.
			\item[Banachraum] Ein Raum wird als \textit{Banachraum} bezeichnet, wenn dieser einen \textit{vollständig normieter Vektorraum} darstellt.
			\item[Hilbert-Raum] Ein Raum wird als \textit{Hilbert-Raum} bezeichnet, wenn dieser einen Banachraum mit einer über \textit{das Skalarprodukt induzierten Norm} darstellt.
		\end{description}
	% end

	\section{Grenzwertsätze}
		Seien $ (a _ n), (b _ n) $ zwei konvergente Folgen in $ \mathbb{K} $.

		\paragraph{Normiertes Argument}
			\[ \liminfty \norm{a _ n} = \norm{\liminfty a _ n} \]
		% end

		\paragraph{Additives Argument}
			\[ \liminfty (a _ n + b _ n) = \liminfty a _ n + \liminfty b _ n \]
		% end

		\paragraph{Konstanten-Argument}
			Sei $ \lambda \in \mathbb{K} $.

			\[ \liminfty \lambda a _ n = \lambda \liminfty a _ n \]
		% end

		\paragraph{Multiplikatives Argument}
			\[ \liminfty (a _ n \cdot b _ n) = \liminfty a _ n \cdot \liminfty b _ n \]
		% end

		\paragraph{Potenz-Argument}
			\[ \liminfty a _ n ^ k = (\liminfty a _ n) ^ k \]
		% end

		\paragraph{Kehrwert-Argument}
			Falls $ \liminfty b _ n \neq 0 $ und $ \forall n \in \mathbb{N} : b _ n \neq 0 $.

			\[ \liminfty \frac{1}{b _ n} = \frac{1}{\liminfty b _ n} \]
		% end

		\paragraph{Divisions-Argument}
			Falls $ \liminfty b _ n \neq 0 $ und $ \forall n \in \mathbb{N} : b _ n \neq 0 $.

			\[ \liminfty \frac{a _ n}{b _ n} = \frac{\liminfty a _ n}{\liminfty b _ n} \]
		% end

		\paragraph{Redizierungs-Argument}
			Falls $ \forall n \in \mathbb{N} : a _ n \leq 0 $. Sei $ k \in \mathbb{N} $.

			\[ \liminfty \sqrt[k]{a _ n} = \sqrt[k]{\liminfty a _ n} \]
		% end

		\paragraph{Monotonie-Regel}
			Gilt $ a _ n \leq b _ n $ für fast alle $ n \in \mathbb{N} $, so gilt: \[ \liminfty a _ n \leq \liminfty b _ n \]
		% end
	% end

	\section{Landau-Symbolik}
		Definition: $ F _ + \coloneqq \{ (a _ n) \text{ Folge in } \mathbb{R} : a _ n > 0 \text{ für alle } n \in \mathbb{N} \} $.

		Sei $ (b _ n) \in F _ + $, dann gilt für die Landau-Symbole:
		\begin{align*}
			O(b _ n) & \coloneqq \{ (a _ n) \in F _ + : (\frac{a _ n}{b _ n}) _ { n \in \mathbb{N} } \text{ beschränkt} \} \tag{Groß-O von $ b _ n $} \\
			o(b _ n) & \coloneqq \{ (a _ n) \in F _ + : \liminfty \frac{a _ n}{b _ n} = 0 \} \tag{Klein-O von $ b _ n $}                              \\
		\end{align*}
		Somit gilt $ o(b _ n) \subseteq O(b _ n) $.
	% end

	\section{Häufungswerte}
		Sei $ (a _ n) $ eine Folge in $ \mathbb{K} $.

		Ein Wert $ p $ heißt \textit{Häufungswert von $ (a _ n) $} gdw. in jeder noch so kleinen Umgebung unendlich viele Folgenglieder liegen. Die Menge der Häufungswerte einer Folge wird als $ HW(a _ n) $ bezeichnet.

		Das Gegenstück zu einem Häufungswert ist ein \textit{isolierter Wert} $ q $, das heißt es existiert eine Umgebung, in der außer $ q $ keine weiteren Elemente aus $ \mathbb{K} $ liegen.

		Eine konvergente Folge hat genau einen Häufungswert, welcher dem Grenzwert entspricht.

		Eine divergente Folge kann beliebig viele Häufungswerte besitzen, gegen welche Teilfolgen konvergieren.

		\paragraph{Beispiel}
			Sei
			\begin{equation*}
				(a _ n) \coloneqq
				\begin{cases}
					\frac{1}{n} & \text{für } n \text{ gerade} \\
					1           & \text{sonst}                 \\
				\end{cases}
			\end{equation*}

			Die Teilfolge $ a _ { 2n } $ konvergiert gegen $ 0 $, also $ 0 \in HW(a _ n) $. Die Teilfolge $ a _ { 2n + 1 } $ konvergiert gegen $ 1 $, also $ 1 \in HW(a _ n) $. Die Folge $ (a _ n) $ selbst divergiert.
		% end
	% end

	\section{Banach'scher Fixpunktsatz}
		Sei $ (V, \norm{\cdot} _ V) $ ein Banachraum, $ M \subseteq V $ abgeschlossen und $ f : M \rightarrow M $ eine Funktion. Weiter existiert ein $ q \in (0, 1) $, sodass für alle $ x, y \in M $ \[ \norm{f(x) - f(y)} _ V \leq q \cdot \norm{x - y} _ V \] gilt.

		Dann gelten folgende Aussagen:
		\begin{itemize}
			\item Es existiert genau ein $ v \in M $ mit $ f(v) = v $ (Fixpunkt). Das heißt es existiert genau ein Fixpunkt in $ M $.
			\item Für jedes $ x _ 0 \in M $ konvergiert die Folge $ (x _ { n + 1 } = f(x _ n)) _ { n \in \mathbb{N} } $ gegen $ v $ und es gelten die folgenden Fehlerabschätzungen für jedes $ n \in \mathbb{N} ^ * $:
				\begin{align*}
					\norm{x _ n - v} _ V & \leq \frac{q ^ n}{1 - q} \norm{x _ 1 - x _ 0} _ V \tag{A-priori-Abschätzung}         \\
					\norm{x _ n - v} _ V & \leq \frac{q}{1 - q} \norm{x _ n - x _ { n - 1 }} _ V \tag{A-posteriori-Abschätzung} \\
				\end{align*}
		\end{itemize}
	% end

	\section{Wichtige Folgen}
		\begin{itemize}
			\item $ \liminfty c = c $, $ c \in \mathbb{R} $
			\item $ \liminfty \frac{1}{n ^ k} = 0 $, $ k \in \mathbb{N} $ (Harmonische Folge)
			\item $ \liminfty \frac{1}{\sqrt[k]{n}} = 0 $, $ k \in \mathbb{N} $
			\item $ \liminfty q ^ n = 0 $, $ q \in \mathbb{K}, \lvert q \rvert < 1 $ (Geometrische Folge)
			\item $ \liminfty \sqrt[n]{c} = 1 $, $ c \in \mathbb{R}, c > 0 $
			\item $ \liminfty \sqrt[n]{n} = 1 $,
			\item $ \liminfty \frac{n ^ k}{z ^ k} = 0 $, $ k \in \mathbb{N} $, $ z \in \mathbb{R}, \lvert z \rvert > 1 $
			\item $ \liminfty n ^ k q ^ n = 0 $, $ k \in \mathbb{N} $, $ q \in \mathbb{R}, \lvert q \rvert < 1 $
			\item $ \liminfty \frac{z ^ n}{n!} = 0 $, $ z \in \mathbb{R}, \lvert z \rvert > 1 $
			\item $ \liminfty \frac{n!}{n ^ n} = 0 $
			\item $ \liminfty (1 + \frac{1}{n}) ^ n = e $ (Eulersche Folge)
			\item $ \liminfty (1 - \frac{1}{n}) ^ n = \frac{1}{e} $ (Eulersche Folge Kehrwert)
		\end{itemize}
	% end
% end

\chapter{Reihen}
	Eine Reihe $ \sum _ { n = 0 } ^ \infty (a _ n) $ beschreibt die unendliche Summe der Folgenglieder einer Folge $ (a _ n) $

	\section{Definitionen}
		\begin{description}
			\item[Partialsumme] Die Partialsummen einer Reihe $ \sum _ { n = 0 } ^ \infty a _ n $ sind darstellbar als eine Folge $ b _ k \coloneqq \sum _ { n = 0 } ^ k (a _ n) $.
			\item[Reihenwert] Der Wert einer Reihe ist definiert als $ \sum _ { n = 0 } ^ \infty a _ n \coloneqq \liminfty b _ n $.
		\end{description}
	% end

	\section{Konvergenzkriterien}
		\paragraph{Trivialkriterium}
			Sei $ \sum _ { n = 0 } ^ \infty a _ n $ eine Reihe in $ \mathbb{K} $.

			Ist $ (a _ n) $ keine Nullfolge, so divergiert die Reihe $ \sum _ { n = 0 } ^ \infty a _ n $.
		% end

		\paragraph{Leibniz-Kriterium}
			Sei $ (a _ n) $ eine Folge in $ \mathbb{K} $.

			Ist $ (a _ n) $ monoton falled, so konvergiert die Reihe $ \sum _ { n = 0 } ^ \infty (-1) ^ { n + k } a _ n $, $ k \in \{ 0, 1 \} $.
		% end

		\paragraph{Majorantenkriterium}
			Seien $ (a _ n), (b _ n) $ Folgen in $ \mathbb{K} $ und $ n _ 0 \in \mathbb{N} $.

			Gilt $ \lvert a _ n \rvert \leq b _ n $ für alle $ n \geq n _ 0 $ und konvergiert die Reihe $ \sum _ { n = 0 } ^ \infty b _ n $, so konvergiert die Reihe $ \sum _ { n = 0 } ^ \infty a _ n $ absolut.
		% end

		\paragraph{Minorantenkriterium}
			Seien $ (a _ n), (b _ n) $ Folgen $ \mathbb{K} $ und $ n _ 0 \in \mathbb{N} $.

			Gilt $ a _ n \geq b _ n \geq 0 $ für alle $ n \geq n _ 0 $ und divergiert die Reihe $ \sum _ { n = 0 } ^ \infty b _ n $, so divergiert auch die Reihe $ \sum _ { n = 0 } ^ \infty a _ n $.
		% end

		\paragraph{Wurzelkriterium}
			Sei $ (a _ n) $ eine Folge in $ \mathbb{K} $.

			Existiert der Grenzwert $ \liminfty \sqrt[n]{\lvert a _ n \rvert} = a $, so ist die Reihe $ \sum _ { n = 0 } ^ \infty a _ n $:
			\begin{equation}
				\begin{cases}
					\text{absolut konvergent} & \text{falls } a < 1 \\
					\text{divergent}          & \text{falls } a > 1 \\
				\end{cases}
			\end{equation}
			\indent Gilt $ a = 1 $, so kann keine Aussage getroffen werden.
		% end

		\paragraph{Quotientenkriterium}
			Sei $ (a _ n) $ eine Folge in $ \mathbb{K} $.

			Existiert der Grenzwert $ \liminfty \lvert \frac{a _ { n + 1 }}{a _ n} \rvert = a $, so ist die Reihe $ \sum _ { n = 0 } ^ \infty a _ n $:
			\begin{equation*}
				\begin{cases}
					\text{absolut konvergent} & \text{falls } a < 1 \\
					\text{divergent}          & \text{falls } a > 1 \\
				\end{cases}
			\end{equation*}
			\indent Gilt $ a = 1 $, so kann keine Aussage getroffen werden.
		% end
	% end

	\section{Cauchy-Produkt}
		Seien $ \sum _ { n = 0 } ^ { \infty } a _ n, \sum _ { n = 0 } ^ \infty b _ n $ Reihen in $ \mathbb{K} $.

		Dann ist gilt für das Produkt $ (\sum _ { n = 0 } ^ { \infty } a _ n) (\sum _ { n = 0 } ^ { \infty } b _ n) $ (Cauchy-Produkt):
		\begin{equation*}
			(\sum _ { n = 0 } ^ { \infty } a _ n) (\sum _ { n = 0 } ^ { \infty } b _ n) = \sum _ { n = 0 } ^ \infty \sum _ { k = 0 } ^ n a _ k b _ { n - k }
		\end{equation*}

		Sind $ \sum _ { n = 0 } ^ { \infty } a _ n $ und $ \sum _ { n = 0 } ^ { \infty } b _ n $ absolut konvergent, so konvergiert auch die Reihe $ \sum _ { n = 0 } ^ \infty \sum _ { k = 0 } ^ n a _ k b _ { n - k } $ absolut und es gilt für die Reihenwerte:
		\begin{equation*}
			(\sum _ { n = 0 } ^ { \infty } a _ n) (\sum _ { n = 0 } ^ { \infty } b _ n) = \sum _ { n = 0 } ^ \infty \sum _ { k = 0 } ^ n a _ k b _ { n - k }
		\end{equation*}
	% end

	\section{Wichtige Reihen}
		\begin{itemize}
			\item $ \suminfty \frac{x ^ n}{n!} = e ^ x $, $ x \in \mathbb{R} $ (Eulersche Reihe)
			\item $ \suminfty (-1) ^ n \frac{x ^ { n + 1 }}{n + 1} = \text{ln}(1 + x) $, $ x \in (-1, 1] $ (Logarithmus)
			\item $ \suminfty (-1) ^ n \frac{x ^ { 2n + 1 }}{(2n + 1)!} = \text{sin}(x) $ (Sinus)
			\item $ \suminfty (-1) ^ n \frac{x ^ { 2n }}{(2n)!} = \text{cos}(x) $ (Kosinus)
			\item $ \suminfty a _ 0 q ^ n = \frac{a _ 0}{1 - q} $, $ q \in \mathbb{R}, \lvert q \rvert < 1 $ (Geometrische Reihe)
			\item $ \suminfty \frac{1}{n ^ k} = \infty $, $ k \in \mathbb{R}, k \leq 1 $ (Harmonische Reihe) \\ Falls $ k = 2 $, gilt $ \suminfty \frac{1}{n ^ 2} = \frac{\pi ^ 2}{6} $
			\item $ \suminfty (-1) ^ { n + 1 } \frac{1}{n} = \text{ln}(2) $ (Alternierende harmonische Reihe)
			\item $ \suminfty (-1) ^ n \frac{1}{2n + 1} = \frac{\pi}{4} $ (Leibnizreihe)
		\end{itemize}
	% end
% end

\chapter{Potenzreihen}
	Eine Potenzreihe ist eine Reihe der Form $ \sum _ { n = 0 } ^ \infty a _ n (x - x _ 0) ^ n $ mit $ (a _ n) $ Folge in $ \mathbb{K} $, $ x \in \mathbb{K} $ und dem Entwicklungspunkt $ x _ 0 $.

	\section{Definitionen}
		\begin{description}
			\item[Konvergenzradius] Der \textit{Konvergenzradius} oder auch \textit{Konvergenzbereich} $ r $ besagt, dass die Potenzreihe für alle $ \lvert x - x _ 0 \rvert < r $ konvergiert und für alle $ \lvert x - x _ 0 \rvert > r $ divergiert. Für $ \lvert x - x _ 0 \rvert $ kann keine Aussage getroffen werden.
		\end{description}
	% end

	\section{Konvergenzkriterien}
		\paragraph{Wurzelkriterium}
			Sei $ \sum _ { n = 0 } ^ \infty a _ n (x - x _ 0) ^ n $ eine Potenzreihe.

			Dann gilt für den Konvergenzradius:
			\begin{align*}
				\sigma & \coloneqq \liminfty \sqrt[n]{\lvert a _ n \rvert} \\
				r      & =
				\begin{cases}
					0                & \text{falls } \liminfty \sqrt[n]{\lvert a _ n \rvert} \text{ nicht existiert} \\
					\infty           & \text{falls } \sigma = 0                                                      \\
					\frac{1}{\sigma} & \text{sonst}
				\end{cases}
			\end{align*}
		% end

		\paragraph{Quotientenkriterium}
			Sei $ \sum _ { n = 0 } ^ \infty a _ n (x - x _ 0) ^ n $ eine Potenzreihe.

			Dann gilt für den Konvergenzradius:
			\begin{align*}
				\sigma & \coloneqq \liminfty \lvert \frac{a _ { n + 1 }}{a _ n} \rvert \\
				r      & =
				\begin{cases}
					0                & \text{falls } \liminfty \sqrt[n]{\lvert a _ n \rvert} \text{ nicht existiert} \\
					\infty           & \text{falls } \sigma = 0                                                      \\
					\frac{1}{\sigma} & \text{sonst}
				\end{cases}
			\end{align*}
		% end
	% end

	\section{Differenzierung}
		Sei $ f(x) $ eine Funktion mit einer Potenzreihe $ \suminfty a _ n (x - x _ 0) ^ n $, sodass gilt $ f(x) = \suminfty a _ n (x - x _ 0) ^ n $, so gilt für die Ableitung $ f'(x) $ \[ f'(x) = \sum _ { n = 1 } ^ \infty n a _ n (x - x _ 0) ^ { n - 1 } \]
	% end
% end

\chapter{Funktionen}
	\section{Definitionen}
		Sei $ f : D \rightarrow \mathbb{R} $, $ D \subseteq \mathbb{R} $ eine Funktion.

		\begin{description}
			\item[Häufungspunkt] $ x _ 0 $ ist ein Häufungspunkt von $ D $, falls es eine Folge $ (a _ n) $ in $ D $ mit $ a _ n \neq x _ 0 $ für ale $ n \in \mathbb{N} $ gibt, welche gegen $ x _ 0 $ konvergiert.
			\item[Isolierter Punkt] Ein isolierte Punkt $ q $ stellt das Gegenstück zu einem Häufungspunkt dar, das heißt es existiert eine Umgebung, in der außer $ q $ keine weiteren Elemente aus $ \mathbb{R} $ liegen.
			\item[Monotonie] Die Funktion $ f $ ist (streng) monoton steigend (bzw. fallend) auf $ D $ gdw. $ f(x) \leq f(x + h) $ (bzw. $ f(x) \geq f(x + h) $) für alle $ x \in D $ und $ h \in \{ r \in \mathbb{R} : r > 0 \} $. Im Falle einer strengen Monotonie gilt dies für $ f(x) < f(x + h) $ (bzw. $ f(x) > f(x + h) $).
		\end{description}
	% end

	\section{Grenzwert}
		\paragraph{Linksseitiger Grenzwert}
			Ist $ x _ 0 $ ein Häufungspunkt von $ D _ - \coloneqq \{ x \in D : x < x _ 0 \} $, so hat $ f $ den linksseitigen Grenzwert $ y $, wenn für jede Folge $ (a _ n) $ in $ D _ + $, welche gegen $ x _ 0 $ konvergiert mit $ a _ n \neq x _ 0 $ für alle $ n \in \mathbb{N} $, gilt, dass die Folge $ (f(a _ n)) $ gegen $ y $ konvergiert.

			\[ \lim _ { x \rightarrow x _ 0 - } \coloneqq \liminfty f(a _ n) = y \]
		% end

		\paragraph{Rechtsseitiger Grenzwert}
			Ist $ x _ 0 $ ein Häufungspunkt von $ D _ + \coloneqq \{ x \in D : x > x _ 0 \} $, so hat $ f $ den rechtsseitigen Grenzwert $ y $, wenn für jede Folge $ (a _ n) $ in $ D _ + $, welche gegen $ x _ 0 $ konvergiert mit $ a _ n \neq x _ 0 $ für alle $ n \in \mathbb{N} $, gilt, dass die Folge $ (f(a _ n)) $ gegen $ y $ konvergiert.

			\[ \lim _ { x \rightarrow x _ 0 + } \coloneqq \liminfty f(a _ n) = y \]
		% end

		\paragraph{Grenzwert}
			Ist $ x _ 0 $ ein Häufungspunkt von $ D $, so hat $ f $ den Grenzwert $ y $, wenn für jede Folge $ (a _ n) $ in $ D $, welche gegen $ x _ 0 $ konvergiert mit $ a _ n \neq x _ 0 $ für alle $ n \in \mathbb{N} $, gilt, dass die Folge $ (f(a _ n)) $ gegen $ y $ konvergiert.

			\[ \limx f(x) \coloneqq \liminfty f(a _ n) = y \]

			Dieser Grenzwert existiert nur dann, wenn sowohl der linksseitige als auch der rechtsseitige Grenzwert existiert und diese identisch sind. Dann gilt:
			\begin{equation*}
				\lim _ { x \rightarrow x _ 0 - } f(x) = \lim _ { x \rightarrow x _ 0 + } f(x) = \limx f(x)
			\end{equation*}
		% end
	% end

	\section{Grenzwertsätze}
		Seien $ f : D \rightarrow \mathbb{R}, g : D \rightarrow \mathbb{R}, h : D \rightarrow \mathbb{R} $, $ D \subseteq \mathbb{R} $ drei Funktionen, sodass die Grenzwerte $ \limx f(x) $ und $ \limx $ existieren.

		\paragraph{Additives Argument}
			\[ \limx (f(x) + g(x)) = \limx f(x) + \limx g(x) \]
		% end

		\paragraph{Multiplikatives Argument}
			\[ \limx (f(x) \cdot g(x)) = \limx f(x) \cdot \limx g(x) \]
		% end

		\paragraph{Betrags-Argument}
			\[ \limx \lvert f(x) \rvert = \lvert \limx f(x) \rvert \]
		% end

		\paragraph{Komparations-Argument}
			\[ (\forall x \in D \setminus \{ x _ 0 \} : f(x) \leq g(x)) \implies (\limx f(x) \leq \limx g(x)) \]
		% end

		\paragraph{Zwischenwert-Argument}
			Gilt $ \limx f(x) = \limx g(x) $ und gilt
			\begin{equation*}
				f(x) \leq h(x) \leq g(x) \text{ für alle } x \in D \setminus \{ x _ 0 \}
			\end{equation*}
			\indent dann gilt auch:
			\begin{equation*}
				\limx f(x) = \limx g(x) \limx h(x)
			\end{equation*}
		% end

		\paragraph{Satz von l'Ho{\^s}pital}
			Seien $ f : D \rightarrow \mathbb{R}, g : D \rightarrow \mathbb{R} $, $ D \subseteq \mathbb{R} $ zwei Funktionen.

			Sind sowohl $ f $ als auch $ g $ stetig und $ g(x) \neq 0 $ für alle $ x \in D $ und konvergieren beide Folgen gegen $ 0 $ ($ \limx f(x) = \limx g(x) = 0 $) oder divergieren beide Folgen bestimmt, so gilt:
			\begin{equation*}
				\limx \frac{f(x)}{g(x)} = \limx \frac{f'(x)}{g'(x)}
			\end{equation*}
		% end
	% end

	\section{Stetigkeit}
		Eine Funktion $ f : D \rightarrow \mathbb{R} $, $ D \subseteq \mathbb{R} $ ist stetig im Punkt $ x _ 0 $ gdw. die folgenden äquivalenten Aussagen gelten:
		\begin{itemize}
			\item $ \forall \varepsilon > 0 : \exists \delta > 0 : (\lvert x - x _ 0 \rvert < \delta \implies \lvert f(x) - f(x _ 0) \rvert < \varepsilon) $
			\item Für jede Folge $ (a _ n) $ in $ D $, die gegen $ x _ 0 $ konvergiert, konvergiert auch die Folge $ (f(a _ n)) $ und es gilt $ \liminfty f(a _ n) = f(x _ 0) $.
		\end{itemize}
		Die Funktion $ f $ ist stetig (auf $ D $) gdw. $ f $ in allen Punktwn $ x \in D $ stetig ist.

		\paragraph{Lipschitz-Stetigkeit}
			Eine Funktion $ f : D \rightarrow \R $, $ D subseteq \R $ ist Lipschitz-stetig auf $ D $ gdw. ein $ L > 0 $ existiert mit:
			\begin{equation}
				\forall x, y \in D : \lvert f(x) - f(y) \rvert \leq L \lvert x - y \rvert
			\end{equation}
			Die Lipschitz-Stetigkeit ist ein strengerer Begriff für die Stetigkeit, das heißt: \[ f \text{ Lipschitz-stetig auf } D \implies f \text{ stetig auf } D \]
		% end
	% end

	\section{Extrema (lokal/global)}
		Sei $ f : D \rightarrow \R $, $ D subseteq \R $ eine Funktion.

		\subsection{Definitionen}
			\begin{description}
				\item[Globales Extrema] $ f $ hat ein globales Maxima (bzw. Minima) in $ x _ 0 \in D $ gdw. $ f(x) \leq f(x _ 0) $ (bzw. $ f(x) \geq f(x _ 0) $) für alle $ x \in D $ gilt.
				\item[Lokales/Relatives Extrema] $ f $ hat ein lokales (oder auch relatives) Maxima (bzw. Minima) in $ x _ 0 \in D $ gdw. ein $ \delta > 0 $ existiert mit $ f(x) \leq f(x _ 0) $ (bzw. $ f(x) \geq f(x _ 0) $) für alle $ x \in D $ mit $ \lvert x - x _ 0 \rvert < \delta $.
				\item[Kritischer Punkt] $ f $ hat einen kritischen Punkt in $ x _ 0 \in D $ gdw. gilt $ f'(x _ 0) = 0 $.
				\item[Konvex] Die Funktion $ f $ heißt konvex (bzw. konkav) gdw. $ f(tx + (1 - t)y) \leq tf(x) + (1 - t)f(y) $ (bzw. $ f(tx + (1 - t)y) \geq tf(x) + (1 - t)f(y) $) für alle $ x, y \in D $ und für alle $ t \in [0, 1] $ gilt. Intuitiv gesprochen bedeuted dies, dass jede Verbindung von zwei auf dem Graph der Funktion liegenden Punkten den Graph der Funktion nicht schneidet. Der komplette Zwischengraph liegt unterhalb (bzw. oberhalb) der Linie. Anders ausgedrückt: Der Epigraph (bzw. Hypograph) der Funktion ist konvex.
				\item[Gerade] Die Funktion $ f $ heißt gerade gdw. $ \forall x \in D : f(x) = f(-x) $ (die Funktion ist Achsensymmetrisch zur y-Achse).
				\item[Ungerade] Die Funktion $ f $ heißt ungerade gdw. $ \forall x \in D : f(x) = -f(-x) $ (die Funktion ist Punktsymmetrisch zum Ursprung).
			\end{description}

			\paragraph{Injektivität/Surjektivität/Bijektivität}
				Sei $ f : A \rightarrow B $ eine Funktion.

				\begin{equation*}
					\text{Dann heißt die Funktion } f
					\begin{cases}
						\text{injektiv}  & \text{falls } \forall x, x' \in A : (f(x) = f(x') \implies x = x') \\
						\text{surjektiv} & \text{falls } \forall y \in B : \exists x \in A : f(x) = y         \\
						\text{bijektiv}  & \text{falls diese injektiv und surjektiv ist}                      \\
					\end{cases}
				\end{equation*}
			% end
		% end

		\subsection{Bestimmung der Extrema}
			Sei $ f : D ^ p \rightarrow \mathbb{R} $, $ D \subseteq \mathbb{R} $, $ p \in \mathbb{N} ^ * $ eine Funktion mit einem kritischen Punkt in $ x _ 0 $.

			\subsubsection{$ p = 1 $}
				Gilt nun $ f'(x) = \cdots = f ^ { n - 1 } (x _ 0) = 0 $, aber $ f ^ n (x _ 0) \neq 0 $, so gilt:
				\begin{equation*}
					\begin{cases}
						f \text{ hat Maxima in } x _ 0 & \text{falls } f ^ n (x) < 0 \\
						f \text{ hat Minima in } x _ 0 & \text{falls } f ^ n (x) > 0 \\
					\end{cases}
				\end{equation*}
				Gilt dies nicht, so ist $ x _ 0 $ kein Extrema (Sattelpunkt).
			% end

			\subsubsection{sonst}
				Wird $ x _ 0 $ in die Hesse-Matrix $ H _ f (x) $ eingesetzt und die Definitheit bestimmt, so gilt:
				\begin{equation*}
					\begin{cases}
						f \text{ hat Maxima in } x _ 0                      & \text{falls } H _ f (x _ 0) \text{ negativ definit}     \\
						f \text{ hat Minima in } x _ 0                      & \text{falls } H _ f (x _ 0) \text{ positiv definit}     \\
						f \text{ hat Maxima oder ist Sattelpunkt in } x _ 0 & \text{falls } H _ f (x _ 0) \text{ negativ semidefinit} \\
						f \text{ hat Minima oder ist Sattelpunkt in } x _ 0 & \text{falls } H _ f (x _ 0) \text{ positiv semidefinit} \\
						f \text{ hat Sattelpunkt in } x _ 0                 & \text{falls } H _ f (x _ 0) \text{ indefinit}           \\
					\end{cases}
				\end{equation*}
			% end
		% end

		\subsection{Zwischenwertsatz}
			Seien $ a, b \in \mathbb{R}, a < b $ gegeben und $ f \in C([a, b]) $. Ist $ y _ 0 \in \mathbb{R}, f(a) \leq y _ 0 \leq f(b) $, so existiert ein $ x _ 0 \in [a, b] $ mit $ f(x _ 0) = y _ 0 $.

			\paragraph{Nullstellen von Banzano}
				Seien $ a, b \in \mathbb{R}, a < b $ und $ f \in C([a, b]) $. Ferner gelte $ f(a)f(b) < 0 $. Dann existiert ein $ x _ 0 \in [a, b] $ mit $ f(x _ 0) = 0 $.
			% end
		% end
	% end

	\section{Taylor}
		\subsection{Definitionen}
			Sei $ I \subseteq \mathbb{R} $ eine offenes Intervall, $ x, x _ 0 \in I $ und $ f \in C ^ \infty (I) $.

			\begin{description}
				\item[Taylorreihe] Die Taylorreihe wird definiert als die Potenzreihe \[ \sum _ { n = 0 } ^ \infty \frac{f ^ {(n)} (x _ 0)}{n!} (x - x _ 0) ^ n \] um den Entwicklungspunkt $ x _ 0 $.
				\item[Taylorpolynom] Das Taylorpolynom wird definiert für jedes $ k \in \mathbb{N} $ als \[ T _ { k; f } (x, x _ 0) \coloneqq \sum _ { n = 0 } ^ k \frac{f ^ {(n)} (x _ 0)}{n!} (x - x _ 0) ^ n \] um den Entiwcklungspunkt $ x _ 0 $.
				\item[Restglied] Das Restglied des $ k\text{-ten} $ Taylorpolynoms ($ k \in \mathbb{N} $) ist definiert als \[ R _ { k, f } (x; x _ 0) \coloneqq \frac{f ^ {(k + 1)} (\xi)}{(k + 1)!} (x - x _ 0) ^ { k + 1 } \] um den Entwicklungspunkt $ x _ 0 $.
			\end{description}
		% end

		\subsection{Satz von Taylor}
			Seien $ I \subseteq \mathbb{R} $ ein offenes Intervall, $ x, x _ 0 \in I $ und für ein $ k \in \mathbb{N} $ $ f : I \rightarrow \mathbb{R} $ eine $ (k + 1)\text{-mal} $ differenzierbare Funktion.

			Dann existiert ein $ \xi $ zwischen $ x $ und $ x _ 0 $, sodass gilt:
			\begin{equation*}
				f(x) = T _ { k, f } (x; x _ 0) + R _ { k, f } (x; x _ 0)
			\end{equation*}
		% end
	% end

	\section{Wichtige Funktionen}
		\label{sec:wichtigefunktionen}

		\begin{table}[ht]
			\centering
			\begin{tabular}{| c | c | c |}
				\hline
				Funktion                             & Ableitung                                  & Stammfunktion                                                         \\
				\hline
				$ f(x) \coloneqq \text{sin}(x) $     & $ f'(x) = \text{cos}(x) $                  & $ F(x) = -\text{cos}(x) $                                             \\
				$ f(x) \coloneqq \text{cos}(x) $     & $ f'(x) = -\text{sin}(x) $                 & $ F(c) = \text{sin}(x) $                                              \\
				$ f(x) \coloneqq \text{tan}(x) $     & $ f'(x) = \frac{1}{\text{cos} ^ 2 (x)} $   & $ F(x) = -\ln(\text{cos}(x)) $                                        \\
				$ f(x) \coloneqq \text{cot}(x) $     & $ f'(x) = -\frac{1}{\text{sin} ^ 2 (x)} $  & $ F(x) = \ln(\text{sin}(x)) $                                         \\
				$ f(x) \coloneqq \text{arcsin}(x) $  & $ f'(x) = \frac{1}{\sqrt{1 - x ^ 2}} $     & $ F(x) = x \cdot \text{arcsin}(x) + \sqrt{1 - x ^ 2} $                \\
				$ f(x) \coloneqq \text{arccos}(x) $  & $ f'(x) = -\frac{1}{\sqrt{1 - x ^ 2}} $    & $ F(x) = x \cdot \text{arccos}(c) - \sqrt{1 - x ^ 2} $                \\
				$ f(x) \coloneqq \text{arctan}(x) $  & $ f'(x) = \frac{1}{1 + x ^ 2} $            & $ F(x) = x \cdot \text{arctan}(x) - \frac{\text{ln}(x ^ 2 + 1)}{2} $  \\
				$ f(x) \coloneqq e ^ { kx } $        & $ f'(x) = k e ^ { kx } $                   & $ F(x) = \frac{1}{k} e ^ { kx } $                                     \\
				$ f(x) \coloneqq \text{sinh}(x) $    & $ f'(x) = \text{cosh}(x) $                 & $ F(x) = \text{sinh}(x) $                                             \\
				$ f(x) \coloneqq \text{cosh}(x) $    & $ f'(x) = \text{sinh}(x) $                 & $ F(x) = \text{cosh}(x) $                                             \\
				$ f(x) \coloneqq \text{tanh}(x) $    & $ f'(x) = \frac{1}{\text{cosh} ^ 2 (x)} $  & $ F(x) = \text{ln}(\text{cosh}(x)) $                                  \\
				$ f(x) \coloneqq \text{arcsinh}(x) $ & $ f'(x) = \frac{1}{\sqrt{1 + x ^ 2}} $     & $ F(x) = x \cdot \text{arcsinh}(x) - \sqrt{x ^ 2 + 1} $               \\
				$ f(x) \coloneqq \text{arccosh}(x) $ & $ f'(x) = \frac{1}{\sqrt{x ^ 2 - 1}} $     & $ F(x) = x \cdot \text{arccosh}(x) - \sqrt{x - 1} \sqrt{x + 1} $      \\
				$ f(x) \coloneqq \text{arctanh}(x) $ & $ f'(x) = \frac{1}{1 - x ^ 2} $            & $ F(x) = \frac{\text{ln}(1 - x ^ 2)}{2} + x \cdot \text{arctanh}(x) $ \\
				$ f(x) \coloneqq \text{ln}(x) $      & $ f'(x) = \frac{1}{x} $                    & $ F(x) = x (\text{ln}(x) - 1) $                                       \\
				$ f(x) \coloneqq \text{ln} _ a (x) $ & $ f'(x) = \frac{1}{x \cdot \text{ln}(a)} $ & $ F(x) = \frac{x (\text{ln}(x) - 1)}{\text{ln}(a)} $                  \\
				\hline
			\end{tabular}
			\caption{Wichtige Funktionen}
		\end{table}
	% end
% end

\chapter{Differentialrechnung}
	Sei $ I \subseteq \mathbb{R} $ ein Intervall.

	\section{Definitionen}
		\begin{description}
			\item[Differenzierbarkeit] Sei $ x _ 0 \in I $. Eine Funktion $ f : I \rightarrow \mathbb{R} $ heißt \textit{differenzierbar in $ x _ 0 $} gdw. der Grenzwert \[ \lim _ { x \rightarrow x _ 0 } \frac{f(x) - f(x _ 0)}{x - x _ 0} = \lim _ { h \rightarrow 0 } \frac{f(x _ 0 + h) - f(x _ 0)}{h} \] existiert. Dieser Grenzwert wird \textit{Ableitung} genannt und als $ f'(x _ 0) $ bezeichnet. Eine Funktion $ f $ heißt \textit{differenzierbar auf $ I $} gdw. diese in allen Punkten $ x _ 0 $ differenzierbar ist. In diesem Fall wird durch $ x \mapsto f'(x) $ für $ x \in I $ eine Funktion $ f' : I \rightarrow \mathbb{R} $ definiert. Diese Funktion heißt Ableitung von $ f $.
		\end{description}
	% end

	\section{Sätze}
		\subsection{Mittelwertsatz der Differentialrechnung}
			Seien $ a, b \in \mathbb{R}, a < b $ und sei $ f \in C([a, b]) $ differenzierbar auf $ (a, b) $.

			Dann existiert ein $ \xi \in (a, b) $, sodass gilt:
			\begin{equation*}
				\frac{f(b) - f(a)}{b - a} = f'(\xi) \text{ bzw. gleichbedeutend } f(b) - f(a) = f'(\xi)(b - a)
			\end{equation*}
		% end

		\subsection{Satz von Rolle}
			Seien $ a, b \in \mathbb{R}, a < b $ und sei $ f \in C([a, b]) $. Ist $ f $ auf $ (a, b) $ differenzierbar und gilt $ f(a) = f(b) $, so existiert ein $ \xi \in (a, b) $ mit $ f'(\xi) = 0 $.
		% end

		\subsection{Zusammenhang mit der Monotonie}
			Sei $ f : I \rightarrow \mathbb{R} $ differenzierbar auf $ I $. Dann gilt:
			\begin{equation*}
				\text{Die Funktion } f \text{ ist auf } I
				\begin{cases}
					\text{konstant}                & \text{falls } f' = 0    \\
					\text{streng monoton wachsend} & \text{falls } f' > 0    \\
					\text{streng monoton fallend}  & \text{falls } f' < 0    \\
					\text{monoton wachsend}        & \text{falls } f' \geq 0 \\
					\text{monoton fallend}         & \text{falls } f' \leq 0 \\
				\end{cases}
			\end{equation*}
		% end

		\subsection{Gleichheit der Ableitung}
			Seien $ f, g : I \rightarrow \mathbb{R} $ differenzbierbar auf $ I $ und gilt $ f' = g' $ auf $ I $, so existiert eine Konstante $ c \in \mathbb{R} $, sodass $ f(x) = g(x) + c $ für alle $ x \in I $ gilt.
		% end
	% end

	\section{Ableitungen}
		Seien $ f, b, h $ Funktionen, $ c \in \mathbb{R} $ und $ n \in \mathbb{N} $.

		\subsection{Regeln}
			\paragraph{Ableitung einer Konstanten}
				\[ f(x) = c \rightarrow f'(x) = 0 \]
			% end

			\paragraph{Ableitung von $ x $}
				\[ f(x) = x \rightarrow f'(x) = 1 \]
			% end

			\paragraph{Potenzregel}
				\[ f(x) = x ^ n \rightarrow f'(x) = n \cdot x ^ { n - 1 } \]
			% end

			\paragraph{Exponentialregel}
				\[ f(x) = n ^ x \rightarrow f'(x) = n ^ x \cdot \text{ln}(n) \]
			% end

			\paragraph{Faktorregel}
				\[ f(x) = c \cdot g(x) \rightarrow f'(x) = c \cdot g'(x) \]
			% end

			\paragraph{Summenregel}
				\[ f(x) = g(x) + h(x) \rightarrow f'(x) = g'(x) + h'(x) \]
			% end

			\paragraph{Differenzregel}
				\[ f(x) = g(x) - h(x) \rightarrow f'(x) = g'(x) - h'(x) \]
			% end

			\paragraph{Produktregel}
				\[ f(x) = g(x) \cdot h(x) \rightarrow f'(x) = g'(x) \cdot h(x) + g(x) \cdot h'(x) \]
			% end

			\paragraph{Quotientenregel}
				\[ f(x) = \frac{g(x)}{h(x)} \rightarrow f'(x) = \frac{g'(x) \cdot h(x) - g(x) \cdot h'(x)}{(h(x)) ^ 2} \]
			% end

			\paragraph{Kettenregel}
				\[ f(x) = g(h(x)) \rightarrow f'(x) = g'(h(x)) \cdot h'(x) \]
			% end

			\paragraph{Radixregel}
				\[ f(x) = \sqrt[n]{x} \rightarrow f'(x) = \frac{1}{n \cdot \sqrt[n]{x}} \]
			% end
		% end
	% end

	\section{Partielle Ableitungen}
		Sei $ f : I ^ n \rightarrow \mathbb{R} ^ m $ eine Funktion.

		Dann wird $ \partial _ k f _ l $ ($ 1 \leq k \leq n $, $ 1 \leq l \leq m $) Die 1. Ableitung der $ l\text{-ten} $ Komponente in Richtung der $ k\text{-te} $ Variable genannt.

		\paragraph{Jacobi-Matrix}
			Die Matrix der ersten partiellen Ableitungen wird Jacobi-Matrix genannt und ist wie folgt definiert:
			\begin{equation*}
				J _ f \coloneqq
				\begin{pmatrix}
					\partial _ 1 f _ 1 & \cdots & \partial _ m f _ 1 \\
					\vdots             & \ddots & \vdots             \\
					\partial _ 1 f _ n & \cdots & \partial _ m f _ n \\
				\end{pmatrix}
			\end{equation*}
		% end

		\paragraph{Gradient}
			$ \nabla _ k f $ bezeichnet den $ k\text{-ten} $ Zeilenvektor der Jacobi-Matrix. Gilt $ n = 1 $, so kann das $ k $ weg gelassen werden und es gilt $ \nabla f = J _ f $.
		% end

		\paragraph{Hesse-Matrix}
			Sei $ n = 1 $.

			Die Matrix der zweiten partiellen Ableitungen wird Hesse-Matrix genannt und ist wie folgt definiert:
			\begin{equation*}
				H _ f \coloneqq
				\begin{pmatrix}
					\partial _ 1 \partial _ 1 f & \cdots & \partial _ m \partial _ 1 f \\
					\vdots                      & \ddots & \vdots                      \\
					\partial _ 1 \partial _ m f & \cdots & \partial _ m \partial _ m f \\
				\end{pmatrix}
			\end{equation*}
		% end
	% end

	\section{Wichtige Ableitungen}
		Siehe \ref{sec:wichtigefunktionen}.
	% end
% end

\chapter{Integralrechnung}
	\section{Ober-/Untersumme und}
		Seien $ a, b \in \mathbb{R}, a < b $, $ Z $ eine Zerlegung von $ [a, b] $ und $ f : [a, b] \rightarrow \mathbb{R} $ beschränkt.

		Ferner seien $ I _ j \coloneqq [x _ { j - 1 }, x _ j] $, $ \lvert I _ j \rvert \coloneqq x _ j - x _ { j - 1 } $, $ m _ j \coloneqq \text{inf } f(I _ j) $ und $ M _ j \coloneqq \text{sup } f(I _ j) $.

		\begin{description}
			\item[Untersumme] Die Summe $ \underline{s} _ f (Z) \coloneqq \sum _ { j = 1 } ^ n m _ j \lvert I _ j \rvert $ heißt die \textit{Untersumme} von $ f $ zu $ Z $.
			\item[Obersumme] Die Summe $ \overline{s} _ f (Z) \coloneqq \sum _ { j = 1 } ^ n M _ j \lvert I _ j \rvert $ heißt \textit{Obersumme} von $ f $ zu $ Z $.
		\end{description}
	% end

	\section{Sätze}
		\subsection{Hauptsatz der Analysis}
			Seien $ a, b \in \mathbb{R}, a < b $ und $ c \in [a, b] $, sowie eine stetige Funktion $ f : [a, b] \rightarrow \mathbb{R} $ gegeben.

			Dann gelten folgende Aussagen:
			\begin{itemize}
				\item Die Funktion $ F : [a, b] \rightarrow \mathbb{R} $ mit $ F(x) \coloneqq \int _ c ^ x \! f(s) \, \mathrm{d}s $, $ x \in I $, ist eine Stammfunktion von $ f $.
				\item Ist $ \Phi : [a, b] \rightarrow \mathbb{R} $ eine Stammfunktion von $ f $, so gilt \[ \Phi(x) = \Phi(c) + \int _ c ^ x \! f(s) \, \mathrm{d}s \quad\text{für alle } x \int [a, b] \]
			\end{itemize}
		% end
	% end

	\section{Integration}
		\subsection{Integrierbarkeit}
			\begin{description}
				\item[Unterintegral] $ \underline{\int _ a ^ b} \! f(x) \, \mathrm{d}x \coloneqq \text{sup } \{ \underline{s} _ f (Z) : Z \text{ Zerlegung von } [a, b] \} $
				\item[Oberintegral] $ \overline{\int _ a ^ b} \! f(x) \, \mathrm{d}x \coloneqq \text{inf } \{ \overline{s} _ f (Z) : Z \text{ Zerlegung von } [a, b] \} $
			\end{description}

			Ferner heißt die Funktion $ f $ auf $ [a, b] $ (Riemann-) Integrierbar, wenn \[ \underline{\int _ a ^ b} \! f(x) \, \mathrm{d}x = \overline{\int _ a ^ b} \! f(x) \, \mathrm{d}x \coloneqq \int _ a ^ b \! f(x) \, \mathrm{d}x \].
		% end

		\subsection{Integrationstechniken}
			\paragraph{Partielle Integration}
				Seien $ f, g \in C ^ 1 (I) $, $ I \subseteq \mathbb{R} $ ein Intervall.

				Dann gilt:
				\begin{equation*}
					\int \! f(x) \cdot g'(x) \, \mathrm{d}x = f(x) \cdot g(x) - \int \! f'(x) \cdot g(x) \, \mathrm{d}x
				\end{equation*}
				und:
				\begin{equation*}
					\int _ a ^ b \! f(x) \cdot g'(x) \, \mathrm{d}x = f(x) \cdot g(x) \Bigr| _ a ^ b - \int _ a ^ b \! f'(x) \cdot g(x) \, \mathrm{d}x
				\end{equation*}
			% end

			\paragraph{Substitution}
				Sei $ f : I \rightarrow \mathbb{C} $ stetig und $ \varphi : [a, b] \rightarrow I $ stetig differenzierbar.

				Dann gilt:
				\begin{equation*}
					\int \! f(\varphi(x)) \cdot \varphi'(x) \, \mathrm{d}x = \int \! f(u) \, \mathrm{d}u \Bigr| _ { u = \varphi{x} }
				\end{equation*}
				und:
				\begin{equation*}
					\int _ a ^ b \! f(\varphi(x)) \cdot \varphi'(x) \, \mathrm{d}x = \int _ { \varphi(a) } ^ { \varphi{b} } \! f(u) \, \mathrm{d}u
				\end{equation*}
			% end
		% end

		\subsection{Uneigentliche Integrale}
			Integrale der Form \[ \int _ a ^ \infty \! f(x) \, \mathrm{d}x \] heißen \textit{uneigentliche Integrale} und es gilt:
			\begin{equation*}
				\int _ a ^ \infty \! f(x) \, \mathrm{d}x \coloneqq \lim _ { b \rightarrow \infty } \int _ a ^ b \! f(x) \, \mathrm{d}x
			\end{equation*}
		% end
	% end

	\section{Fourierreihen}
		Seien $ N \in \mathbb{N} $, $ \omega > 0 $ und $ (a _ n), (b _ n) $ Reihen in $ \mathbb{R} $ mit $ a _ N, b _ n \neq 0 $.

		Dann heißt \[ P(x) = \frac{a _ 0}{2} \sum _ { k = 1 } ^ N (a _ n \text{cos}(n \omega x) + b _ n \text{sin}(n \omega x)) \] ein \textit{Trigonometrisches Polynom} des Grades $ N $ mit der Frequenz $ \omega $.

		Sei im folgenden $ T \coloneqq \frac{2\pi}{\omega} \iff \omega = \frac{2\pi}{T} $ (Periode).

		Es gilt zur Approximation einer Funktion $ f(x) $ mit der Periode $ T $ ($ n \in \mathbb{N} $):
		\begin{align*}
			(a _ n) & \coloneqq \frac{2}{T} \int _ { - \frac{T}{2} } ^ \frac{T}{2} \! f(x) \text{cos}(n \omega x) \, \mathrm{d}x \\
			(b _ n) & \coloneqq \frac{2}{T} \int _ { - \frac{T}{2} } ^ \frac{T}{2} \! f(x) \text{sin}(n \omega x) \, \mathrm{d}x \\
		\end{align*}
		Das entstehende trigonometrische Polynom heißt $ F _ { f, N } (x) $ ($ N $ ist der Grad des Polynoms) und es gilt für $ N = \infty $: $ f(x) = F _ { f, \infty } (x) $.
	% end
% end

\chapter{Differentialgleichungen}
Eine Gleichung der Form \[ 0 = F(t, y(t), \cdots, y ^ {(n)}(t)) \] heißt (gewöhnliche) \textit{Differentialgleichung} der Ordnung $ n $. Meist sind Differentialgleichungen nach der höchsten Ableitung aufgelöst: \[ y ^ {(n)} (t) = f(t, y(t), \cdots, y ^ {(n - 1)} (t)) \]

Sind an einer Stelle $ t _ 0 $ bestimmte Anfangswerte \[ y(t _ 0) = y _ 0, \cdots, y ^ {(n - 1)} (t _ 0) = y _ { n - 1 } \] gegeben, so wird dies ein \textit{Anfangswertproblem} genannt.

\paragraph{Lineare Differentialgleichungen erster Ordnung}
	\label{p:dgllinear}

	Eine lineare Differentialgleichung erster Ordnung hat die allgemeine Form $ y'(t) + a(t)y(t) = b(t) $.
% end

\paragraph{Lineare Systeme erster Ordnung mit konstanten Koeffizienten}
	Ein System lineare Differentialgleichungen mit konstanten Koeffizienten hat die allgemeine Form
	\begin{equation*}
		y'(t) = Ay(t) + b(t)
	\end{equation*}
	auf einem Intervall $ I \subseteq \mathbb{R} $ mit einer stetigen Funktion $ b : I \rightarrow \mathbb{R} ^ N $ und einer Matrix $ A \in \mathbb{R} ^ { N \times N } $.
% end

\paragraph{Differentialgleichungen höherer Ordnung}
	Differentialgleichungen der Ordnung $ n \geq 2 $ lassen sich immer auf ein System von Differentialgleichungen erster Ordnung reduzieren.

	Sei $ y ^ {(n)} (t) = F(t, y(t), y'(t), \cdots, y ^ {(n - 1)} (t)) $ eine Differentialgleichung mit $ n \geq 2 $ und $ F : I \times \mathbb{R} ^ n \rightarrow \mathbb{R} $ stetig.

	Sei $ v : I \rightarrow \mathbb{R} ^ n $ eine Funktion mit \[ v _ 1 = y, v _ 2 = y', \cdots, v _ n = y ^ {( n - 1 )} \] für welche dann gilt:
	\begin{equation*}
		v'(t) =
		\begin{pmatrix}
			v' _ 1 (t)         \\
			v' _ 2 (t)         \\
			\vdots             \\
			v' _ { n - 1 } (t) \\
			v' _ n (t)         \\
		\end{pmatrix}
		=
		\begin{pmatrix}
			y'(t)             \\
			y''(t)            \\
			\vdots            \\
			y ^ {(n - 1)} (t) \\
			y ^ {(n)} (t)     \\
		\end{pmatrix}
		=
		\begin{pmatrix}
			v _ 2 (t)                           \\
			v _ 3 (t)                           \\
			\vdots                              \\
			v _ n (t)                           \\
			F(t, v _ 1 (t), \cdots, v _ n (t2)) \\
		\end{pmatrix}
	\end{equation*}

	\todo{Wie geht das?}
% end

\section{Typen}
	\begin{description}
		\item[autonom] $ y ^ {(n)} (t) $ heißt \textit{autonom} gdw. diese nicht von $ t $ abhängt.
		\item[homogen] $ y'(t) $ heißt \textit{homogen} gdw. diese nur von $ \frac{y(t)}{t} $ abhängt, das heißt ex existiert eine Funktion $ g : \mathbb{R} \rightarrow \mathbb{R} $, sodass $ y'(t) = f(t, y(t)) = g(\frac{y(t)}{t}) $. Lineare Differentialgleichungen heißen \textit{homogen} gdw. für alle $ t \in I $ gilt $ b(t) = 0 $.
		\item[inhomogen] Lineare Differentialgleichungen heißen \textit{inhomogen} gdw. nicht für alle $ t \in I $ gilt $ g(t) = 0 $.
		\item[linear] Siehe \ref{p:dgllinear}.
	\end{description}
% end

\section{Fundamentalsystem}
	\paragraph{Homogene lineare Systeme}
		Sei $ y'(t) = Ay(t) $ ein homogenes lineares System mit der konstanten Matrix $ A \in \mathbb{R} ^ { N \times N } $, dann bildet die Matrix $ e ^ { tA } $ ein Fundamentalsystem.

		Ist $ A $ diagonalisierbar mit den Eigenwerte $ \lambda _ 1, \cdots, \lambda _ N $ mit den Eigenvektoren $ v _ 1, \cdots, v _ N $. Dann ist \[ \{ e ^ { t \lambda _ 1 } v _ 1, \cdots, e ^ { t \lambda _ N } v _ N \} \] eine Fundamentalsystem der Gleichung $ y'(t) = Ay(t) $.
	% end

	\paragraph{Inhomogene lineare Systeme}
		Sei $ y'(t) = Ay(t) + b(t) $ ein inhomogenes lineares System mit dem Anfangswert $ y(t _ 0) = y _ 0 $.

		Dann lautet die eindeutige globale Lösung:
		\begin{equation*}
			y(t) = e ^ { (t - t _ 0)A } y _ 0 + e ^ { tA } \int _ { t _ 0 } ^ t \! e ^ { -sA } b(s) \, \mathrm{d}s = e ^ { (t - t _ 0) A } y _ 0 + \int _ { t _ 0 } ^ t \! e ^ { (t - s) A } b(s) \, \mathrm{d}s
		\end{equation*}
	% end
% end

\section{Sätze}
	\subsection{Satz von Picard-Lindelöff}
		Sei $ I \subseteq \mathbb{R} $ ein Intervall, $ f : I \times \mathbb{R} ^ n \rightarrow \mathbb{R} ^ n $ stetig, $ t _ 0 \in I $ und $ y _ 0 \in \mathbb{R} ^ n $.

		Ist nun $ f $ Lipschitz-stetig, d.h. es existiert ein $ L > 0 $, sodass für alle $ t \in I $ und $ y _ 1, y _ 2 \in \mathbb{R} ^ n $ gilt \[ \norm{f(t, y _ 1) - f(t, y _ 2)} \leq L\norm{y _ 1 - y _ 2} \] dann existiert ein kompaktes Intervall $ J \subseteq I $ mit $ t _ 0 \in J $, sodass das Anfangswertproblem
		\begin{equation*}
			\text{AWP }
			\begin{cases}
				y'(t) = f(t, y(t)) \\
				y(t _ 0) = y _ 0
			\end{cases}
		\end{equation*}
		eindeutig lösbar ist.
	% end
% end

\section{Lösungsmethoden}
	\paragraph{Trennung der Variablen}
		Sei auf einem Intervall $ I \subseteq \mathbb{R} $ mit stetigen Funktionen $ f : \mathbb{R} \rightarrow \mathbb{R} $, $ g : I \rightarrow \mathbb{R} $, sowie $ t _ 0 \in I $ und $ y _ 0 \in \mathbb{R} $ das Anfangswertproblem
		\begin{equation*}
			\text{AWP }
			\begin{cases}
				y'(t) = g(t) \cdot f(y(t)) \\
				y(t _ 0) = y _ 0           \\
			\end{cases}
		\end{equation*}
		gegeben.

		Ist $ f(t _ 0) \neq 0 $, so gilt:
		\begin{equation*}
			y(t) = F ^ { -1 } (G(t)) \quad\text{mit}\quad G(t) \coloneqq \int _ { t _ 0 } ^ t \! g(\tau) \, \mathrm{d}\tau \quad\text{und}\quad F(y) \coloneqq \int _ { y _ 0 } ^ y \! \frac{1}{f(\eta)} \, \mathrm{d}\eta
		\end{equation*}
		Alternativ kann $ y(t) $ berechnet werden durch $ \int _ { y _ 0 } ^ { y(t) } \! \frac{1}{f(\eta)} \, \mathrm{d}\eta = \int _ { t _ 0 } ^ { t } \! g(\tau) \, \mathrm{d}\tau $. Ist kein Anfangswert gegeben, so werden unbestimme Integrale genutzt. Das Ergebnis enthält dann eine Konstane $ c $, welche durch den Anfangswert bestimmt werden kann.
	% end

	\paragraph{Variation der Konstanten}
		Sei auf einem Intervall $ I \subseteq \mathbb{R} $ mit $ a, b \in C(I) $, sowie $ t _ 0 \in I $ und $ y _ 0 \in \mathbb{R} $ das lineare Anfangswertproblem
		\begin{equation*}
			\text{AWP }
			\begin{cases}
				y'(t) + a(t)y(t) = b(t) \\
				y(t _ 0) = y _ 0
			\end{cases}
		\end{equation*}
		gegeben.

		Dann existiert genau eine globale Lösung, welche durch
		\begin{equation*}
			y(t) = e ^ { -A(t) } y _ 0 + e ^ { -A(t) } \int _ { t _ 0 } ^ t \! b(s) e ^ { A(s) } \, \mathrm{d}s \quad\text{mit}\quad A(t) \coloneqq \int _ { t _ 0 } ^ t \! a(s) \, \mathrm{d}s
		\end{equation*}
		gegeben ist.
	% end

	\paragraph{}
	% end
% end

\chapter{Trigonometrie/Hyperfunktionen}
	\section{Komplexe Zahlen}
		Sei $ i $ die imaginäre Zahl.

		\subsection{Darstellungen}
			Eine komplexe Zahl $ z \in \mathbb{C} $ kann unterschiedlich Dargestellt werden. Die gebräuchlichsten Darstellungen ist die der kartesischen Koordinaten und die Darstellung durch Polarkoordinaten.

			\paragraph{Kartesische Koordinaten}
				Die Darstellung $ z = a + bi $ wird die kartesiche Darstellung genannt.

				Zur Umwandlung von Polarkoordinaten in kartesische Koordinaten gilt:
				\begin{align*}
					a & = r \cdot cos(\varphi) \\
					b & = r \cdot sin(\varphi) \\
				\end{align*}
			% end

			\paragraph{Polarkoordinaten}
				Die Darstellung $ z = (r, \varphi) $ (oder auch $ z = r \cdot e ^ \varphi $) wird die Darstellung durch Polarkoordinaten genannt. Für $ \varphi $ muss ein Intervall der größe $ 2\pi $ festgelegt werden, da beispielsweise $ (1, \pi) = (1, 3\pi) $, was verwirren kann. Meist wird mit $ (-\pi, \pi] $ oder $ [0, 2\pi) $ gearbeitet.

				Zur Umwandlung von kartesischen Koordinaten in Polarkoordinaten gilt:
			% end

			\paragraph{Umrechnung}
				Für die Umrechnung von $ z \in \mathbb{C} $ zwischen $ z = a + bi $ ($ a, b \in \mathbb{R} $) und $ z = (r, \varphi) $ ($ r \in \mathbb{R} $, $ \varphi \in (-\pi, \pi] $) gilt:
				\begin{align*}
					a       & = r \cdot cos(\varphi) \\
					b       & = r \cdot sin(\varphi) \\
					r       & = \sqrt{a ^ 2 + b ^ 2} \\
					\varphi & =
					\begin{cases}
						arctan(\frac{b}{a})       & \text{falls } x > 0                \\
						arctan(\frac{b}{a}) + \pi & \text{falls } x < 0 \land y \geq 0 \\
						arctan(\frac{b}{a}) - \pi & \text{falls } x < 0 \land y < 0    \\
						\frac{\pi}{2}             & \text{falls } x = 0 \land y > 0    \\
						-\frac{\pi}{2}            & \text{falls } x = 0 \land y < 0    \\
					\end{cases}
				\end{align*}
			% end
		% end
	% end
% end
