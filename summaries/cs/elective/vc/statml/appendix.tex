\chapter{Self-Test Questions}
	The text below also contains answers for the self-test questions! To prevent you from reading the answers accidentally, the questions start on a new page after the demo questions.

	\section{Demo}
		\paragraph{In what case can you toggle the visibility of the answers?}
			\answer{If my PDF viewer supports it.}

		\paragraph{In what case can you definitely not toggle the visibilities of the answers?}
			\answer{If I have printed the document.}
			% end

			\newpage

	\section{Organization}
		\paragraph{What are some of Machine Learning applications?}
			\answer{For example natural language processing and autonomous driving.}

		\paragraph{When can we benefit from using Machine Learning methods?}
			\answer{Machine learning can be helpful if the problem is too hard to program by hand (e.g. image recognition and natural language processing).}

		\paragraph{What are the different types of learning?}
			\answer{
				\begin{itemize}
					\item Supervised: Given labeled data (input/output pairs).
					\item Unsupervised Given unlabeled data (only input).
					\item Semi-Supervised:  Given some labeled and some unlabeled data.
					\item Reinforcement Learning: No data given.
				\end{itemize}
			}

		\paragraph{What is the difference between classification and regression? Can you give some examples of both tasks (and identify the domain and codomain)?}
			\answer{
				\begin{itemize}
					\item Classification sorts data into discrete classes. A sample use case is the recognition of hand-written digits. The domain are images and the codomain are the number from zero to one.
					\item Regression maps data onto a continuous output space and is able to extrapolate missing data. A sample use case is the analysis and prediction of weather. The domain are date or date-times and the codomain may be the temperature.
				\end{itemize}
			}

		\paragraph{What are the challenges when solving a Machine Learning problem?}
			\answer{
				\begin{itemize}
					\item Generalization: The learned function should generalize and work for new data and not only for the training data, called
					\item Overfitting: The algorithm just "memorized" the learning data and cannot handle other (new) data.
					\item Features: Choosing the right features is hard but important.
					\item Curse of dimensionality: Too high-dimensional features cause problems.
				\end{itemize}
			}

		\paragraph{What is generalization? What is overfitting?}
			\answer{Overfitting is quite the opposite of generalization. If an algorithm overfits, it just memorizes the training data and is not capable of handling new data. If it is, the function ha generalized.}
			% end

	\section{Linear Algebra Refresher}
		\paragraph{Remember vectors and what you can do with them.}
			\answer{Yeah I do remember.}

		\paragraph{Remember matrices and what you can do with them.}
			\answer{Yeah I do remember.}

		\paragraph{What is a projection? How do you use it?}
			\answer{N/A} % TODO: Q&A: Answer.

		\paragraph{How to compute the inverse of a matrix?}
			\answer{One method is the Gaussian algorithm: You write the identity matrix to the right and the given matrix to the left and then transform both matrices in parallel until the identity matrix is on the left. Then the inverse is on the right.}

		\paragraph{What are Eigenvalues and Eigenvectors?}
			\answer{The eigenvectors of a matrix are those (non-trivial) vectors that do not get rotated but only scaled when multiplied by the matrix. The corresponding eigenvalue of an eigenvector is the factor it gets scaled by.}

		\paragraph{What is a change of basis? What is a linear transformation? Are they the same?}
			\answer{N/A} % TODO: Q&A: Answer.
			% end

	\section{Statistics Refresher}
		\paragraph{What is a random variable?}
			\answer{A random variable is a variable that can have multiple values that, if randomly sampled, follow a specific probability distribution.}

		\paragraph{What is a distribution?}
			\answer{A probability distribution defines the probability that the value of a random variable falls into a specific region or has a specific value. It maps all possible values of the domain onto a probability between \(0\) and \(1\).}

		\paragraph{What is a Binomial distribution?}
			\answer{The binomial distribution \(\textrm{Bin}(k \given N, \mu)\) is the probability that in \(N\) trials with the singular probability \(\mu\) exactly \(k\) trials have been a success.}

		\paragraph{How does a Poisson distribution relate to Binomial distributions?}
			\answer{The Poisson distribution is the Binomial distribution with \( N \to \infty \).}

		\paragraph{What is a Gaussian distribution?}
			\answer{The Gaussian distribution is the most common probability distribution and has some neat properties, e.g. that the sum of \( N \to \infty \) random i.i.d. variables is Gaussian distributed. Its density function is given as \[ \mathcal{N}\,(x \given \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\Bigg\{ -\frac{(x - \mu)^2}{2\sigma^2} \Bigg\} \]}

		\paragraph{What is an expectation?}
			\answer{The expectation value \(\E(X)\) of a random variable \(X\) is the value that the random variable has in the mean. For continuous distributions with probability density \( p(x) \), the expectation value is given as \[ \E(X) = \int_{-\infty}^{\infty} x p(x) \dd{x} \]}

		\paragraph{What is a joint distribution?}
			\answer{A joint distribution \( p(x_1, \cdots, x_n) \) of \(n\) random variables is the probability that the tuple of both numbers fall into any particular range of set of values. For independent variables the distribution is \( p(x, y) = p(x) \, p(y) \)}

		\paragraph{What is a conditional distribution?}
			\answer{The conditional distribution \( p(x \given y) \) is the probability of \(x\) given that \(y\) is true. It is given as \[ f(x \given y) = \frac{f(x, y)}{f(y)} \]}

		\paragraph{What is a distribution with a lot of information?}
			\answer{N/A} % TODO: Q&A: Answer. (High Entropy?)

		\paragraph{How to measure the difference between distributions?}
			\answer{The difference (or similarity) between distribution can be measured using the Kullback-Leibler divergence (KL-divergence): \[ \textrm{KL}(p \,\Vert\, q) = -\int p(x) \, \ln \frac{q(x)}{p(x)} \dd{x} \]}
			% end

	\section{Optimization Refresher}
		\paragraph{Why is optimization important for machine learning?}
			\answer{Every machine learning problem is an optimization problem or can be reduced to be one.}

		\paragraph{What do well-formulated learning problems look like?}
			\answer{
				Well-formulated problems have a cost function \( J(\theta) \) that has to be minimized or maximized, given some equality constraints \( f(\theta) = 0 \) and some inequality constraints \( g(\theta) \geq 0 \). It is commonly notated like this:
				\begin{align*}
					\arg\min\limits_\theta \, J(\theta) &        \\
					\textrm{s.t.} \quad
					f(\theta)                           & = 0    \\
					g(\theta)                           & \geq 0
				\end{align*}
				Every minimization problem can be a maximization problem and vice versa by multiplying the cost function with \(-1\).
			}

		\paragraph{What is a convex set and what is a convex function?}
			\answer{A convex set is a set where every point that lies on a line between any two points is also part of the set. Similarly, for a convex function, every line that can be drawn between any two points of the function does not cross the function. Formal: A set \( C \subseteq \R^n \) is convex iff \[ \forall \vec{x}, \vec{y} \in C : \forall \alpha \in [0, 1] : \alpha\vec{x} + (1 - \alpha)\vec{y} \in C \] and a function \( f : \R^n \to \R \) is convex iff \[ \forall \vec{x}, \vec{y} \in \textrm{Domain}(f) : \forall \alpha \in [0, 1] : (\alpha\vec{x} + (1 - \alpha)\vec{y}) \leq \alpha f(\vec{x}) + (1 - \alpha) f(\vec{y}) \]}

		\paragraph{How do I find the maximum of a vector-valued function?}
			\answer{Take the gradient w.r.t. to the variable, yielding a vectorial gradient. Then set each component to zero and solve for the variable (this may be complicated due to overdetermined equation systems and similar).}

		\paragraph{How to deal with constrained optimization problems?}
			\answer{Formulate the Lagrangian \( L(\theta) = J(\theta) + \lambda f(\theta) + \mu g(\theta) \), take the derivatives w.r.t. \(\theta\) and the Lagrangian multipliers \(\lambda\) and \(\mu\), set them to zero and solve for \(\theta\).}

		\paragraph{How to solve such problems numerically?}
			\answer{One method for solving them is gradient descent, also called steepest descent. It works by calculating the gradient and then reducing the value of \(\theta\) by the gradient iteratively. For maximization, the gradient has to be added.}
			% end

	\section{Bayesian Decision Theory}
		\paragraph{How can we decide on classifying a query based on simple and general loss functions?}
			\answer{N/A} % TODO: Q&A: Answer. (Bayes Rule?)

		\paragraph{What does "Bayes Optimal" mean?}
			\answer{A "Bayes optimal" classifier obeys the rule that it chooses class \(C_1\) over \(C_2\) iff \( \frac{p(x \given C_1)}{p(x \given C_2)} > \frac{p(C_2)}{p(C_1)} \).}

		\paragraph{How to deal with two or more classes?}
			\answer{Choose class \( C_i \) iff \( \frac{p(x \given C_i)}{p(x \given C_j)} > \frac{p(C_j)}{p(C_i)} \quad \forall i \neq j \).}

		\paragraph{How to deal with high dimensional feature vectors?}
			\answer{The decision rules still apply, but the posterior probability densities \( p(\vec{x} \given C_k) \) have to handle multiple features (be multivariate).}

		\paragraph{How to incorporate prior knowledge on the class distribution?}
			\answer{This is done through the prior \( p(C_k) \) for class \(C_k\) which can be determined, e.g. by simple counting (if and only if the sample data points are representative).}

		\paragraph{What are the equations for misclassification rate and risk?}
			\answer{The risk can be encoded as \( \lambda(\alpha_i \given C_j) \), which is the loss of classifying \( x \) as class \(C_i\) if \( C_j \) is the actual class. The risk is then encoded as \( R(\alpha_i \given x) = \E_{C_k \sim p(C_k \given x)} \big(\lambda(\alpha_i \given C_k)\big) = \sum_j \lambda(\alpha_i \given C_j) \, p(C_j \given x) \) which is the expected risk for classifying \(x\) as class \(C_i\). Then decide for the class with the lowest risk.}
			% end

	\section{Probability Density Estimation}
		\paragraph{Where do we get the probability of data from?}
			\answer{The probability densities can be estimated if sample data is available. This problem is called "Probability Density Estimation".}

		\paragraph{What are parametric methods and how to obtain their parameters?}
			\answer{Parametric models depend on distributions like Gaussians that have specific parameters (e.g. the mean \(\mu\) and the variance \(\sigma^2\)). The values of these parameters can then by obtained by estimation, e.g. vi maximum likelihood or maximum a-posteriori, where the last one is a Bayesian approach.}

		\paragraph{How many parameters have non-parametric methods?}
			\answer{Non-parametric models have any number of parameters as the raw data is used as "parameters".}

		\paragraph{What are mixture models?}
			\answer{Mixture models are built out of multiple single probability densities. They are all added together with a prior \(\pi_i\), which is the probability that a data point is samples from the \(i\)-th distribution (also called "weight"). The general formula is \( p(x) = \sum_i \pi_i p_i(x) \), where \(\pi_i\) is the prior and \(p_i(x)\) is the \(i\)-th probability density.}

		\paragraph{Should gradient methods be used for training mixture models?}
			\answer{No, because the derivatives of these models contain cyclic dependencies on the other parameters which makes gradient methods mostly useless and slow.}

		\paragraph{How does the EM algorithm work?}
			\answer{
				The whole idea behind EM is to maximize the complete log-likelihood \( Q(\theta, \theta^{i - 1}) = \int p(y \given X, \theta^{(i - 1)}) \, \ln p(X, y \given \theta) \dd{\theta} \) in two steps:
				\begin{itemize}
					\item E-Step: Compute the probability density \( p(y \given X, \theta^{(i - 1)}) \) using the previously estimated (or initialized) parameters \( \theta^{(i - 1)} \).
					\item M-Step: Maximize the complete log-likelihood w.r.t. \( \theta \) with maximum likelihood by using the values that have been computed in the E-Step.
				\end{itemize}
			}

		\paragraph{What is the biggest problem of mixture models?}
			\answer{The number of components and type of components that were used to draw the samples are typically unknown and it is (currently) impossible to determine them by an algorithm. There are some heuristics and trial and error can be used, but no more.}
			% end

	\section{Clustering and Evaluation}
		\paragraph{How can we find meaningful clusters in the data?}
			\answer{Cluster can be found, e.g. with mean shift clustering that starts at every data point and builds up nets of data points that are nearby (by climbing up the gradient). Another method is, for example, \(k\)-means.}

		\paragraph{How does density estimation with mixture models relate to clustering?} % TODO: Q&A: Check.
			\answer{Mixture models can generate clustered data, this can the estimation of them yield an estimation which pile of data was generated by which component. Thus, mixture model estimation is kind of a more powerful clustering method as it also yields the densities.}

		\paragraph{What is the bias-variance trade-off?}
			\answer{An estimator can typically have a low bias or a low variance, but not both.}

		\paragraph{What is a BLUE estimator?}
			\answer{An BLUE estimator ("best linear unbiased estimator") is an MVUE estimation that is linear in its features. An MVUE estimation has zero bias and a minimum of variance (called "minimum variance unbiased estimator").}

		\paragraph{Are maximum likelihood estimators always unbiased?}
			\answer{No, they are not. E.g. the MLE for the variance of a Gaussian is biased with \( \Bias(\hat{\sigma}^2) = -\frac{1}{N} \sigma^2 \) where \(N\) is the number of samples and \(\sigma^2\) is the real variance.}

		\paragraph{What is leave on out cross-validation? What do we need it for?}
			\answer{In LOOCV, the whole data set is used for training with the exception of one data point that is used for testing. It is needed if not so many data is available to detect overfitting and to validate the model in general.}
			% end

	\section{Regression}
		\paragraph{What is regression (in general) and linear regression (in particular)?}
			\answer{Regression maps an input space to a continuous output space. Linear regression depends on function \( y(\vec{x}) = \vec{w}^T \phi(\vec{x}) \) that are linear in the parameters.}

		\paragraph{What is the cost function of regression and how can I interpret it?}
			\answer{The cost function of regression defines the penalty for a misclassified sample (e.g. least squares). The goal is to minimize this loss function and to have a way to get an actual value from the calculated probability density. This loss function is then minimized w.r.t. to the regression function \( f(\vec{x}) \) to get the actual function value. For least squares, this is just mean of he probability density, thus equal to \( f(\vec{x}) \).}

		\paragraph{What is overfitting?}
			\answer{If the regressor overfits, it perfectly goes through the data points but does not really follow the actual function. This is due to the regressor just "memorizing" where the data points lie without generalizing.}

		\paragraph{How can I derive a Maximum-Likelihood Estimator for Regression?}
			\answer{For MLE for regression, the given samples must be generated with some noise \( \epsilon \) following some probability distribution, e.g. Gaussian \( \epsilon \sim \mathcal{N}\,(0, \beta^{-1}) \). The function value then also is a random variable \( y \sim \mathcal{N}\,\big(f(\vec{x}), \beta^{-1}\big) \). An estimator for \( f(\vec{x}) \) and the precision \(\beta\) can then be derived by using the typical ML approach (take the derivative of the log-likelihood, set it to zero).}

		\paragraph{Why are Bayesian methods important?}
			\answer{Bayesian methods allow to tame overfitting by putting a prior on the parameters, thus generating a probability distribution over the parameters. This gives much better and more accurate results.}

		\paragraph{What is MAP and how is it different to full Bayesian regression?}
			\answer{MAP is like the ML approach to regression, but instead of maximizing the likelihood, the posterior \( p(\vec{w} \given X, \vec{y}, \alpha, \beta) \propto p(\vec{y} \given X, \vec{w}, \beta) \, p(\vec{w}, \alpha) \) is maximized. This allows to put a prior on the parameters and thus regularizing the overfitting.}
			% end

	\section{Classification}
		\paragraph{How do we get from Bayesian optimal decisions to discriminant functions?} % TODO: Q&A: Check.
			\answer{Discriminant functions model the class-conditional posterior that is used in Bayes decision rule directly, e.g. \( y_1(x) = p(C_1 \given x) \) and \( y_2(x) = p(C_2 \given x) \) with a combined discriminant function \( y(x) = y_1(x) - y_2(x) \). Then decide for class \(C_1\) iff \( y(x) > 0 \) and for class \( C_2 \) iff \( y(x) < 0 \), this is equivalent the Bayes optimal decision rule.}

		\paragraph{How to derive a discriminant function from a probability distribution?} % TODO: Q&A: Check.
			\answer{Given class-conditional posteriors \( p(C_1 \given x) \) and \( p(C_2 \given x) \), a discriminant function can be derived as \( y(x) = p(C_1 \given x) - p(C_2 \given x) \) and similar if only the likelihood and the prior are given (the normalization term can be abandoned as its the same for both distributions, like in Bayes decision like).}

		\paragraph{How to deal with more than two classes?}
			\answer{Build each discriminant function \( y_i(x) \) to formulate how strong the classifiers believes in that class. Then decide for class \( C_i \) iff \( y_i(x) > y_j(x) \) for all \( i \ne qj \).}

		\paragraph{What does "linearly separable" mean?}
			\answer{Intuitively, a line (or hyperplane) can be drawn through all data points while perfectly separating them (one class on the one side and the other on the other).}

		\paragraph{What is Fisher discriminant analysis? How does it relate to regression?} % TODO: Q&A: Check.
			\answer{Fisher's discriminant analysis finds a projection through the data points where the data points then can be separated by a decision boundary (which is not given by Fisher's discriminant analysis). This projection is similar to regression as it also finds a "line" through the data.}

		\paragraph{Is Fisher's linear discriminant Bayes optimal?}
			\answer{Yes, if the classes have equal and diagonal class-conditional likelihood covariance matrices.}

		\paragraph{What are perceptrons? How can we train them?} % TODO: Q&A: Check.
			\answer{Perceptrons are simple neural networks, typically with no hidden layer and just one output neuron. The basic perceptron (no hidden layer, one output neuron with the sign-"activation function") is trained using the perceptron algorithm which is a version of gradient descent with the gradients "inserted".}

		\paragraph{What is logistic regression? How can be derive the parameter update rule?}
			\answer{Logistic regression formulates the class-conditional posterior as \( p(C_1 \given x) = \sigma(a) \) where it assumes that \(a\) is given by some linear discriminant function \( a = \vec{w}^T \vec{x} + w_0 \). The parameter update rule can then be derived by applying maximum likelihood estimation and then to gradient descent.}
			% end

	\section{Linear Dimensionality Reduction and Statistical Learning Theory}
		\paragraph{What does dimensionality reduction mean?}
			\answer{The goal is to find a dimension \( D \ll N \) that is lower than the original dimension \(N\), e.g. to reduce the computation cost in kernel regression (where a \( D \times D \) matrix has to be inverted) or to visualize the data.}

		\paragraph{What is PCA? What are the three things that it does?} % TODO: Q&A: PCA, three things?
			\answer{Principal component analysis (PCA) finds the principal components of the data. That is, it finds the directions in which the variance is the highest and finds how high the variance is in this directions. It also finds the so-called "explained variance", the amount of variance a component direction explains.}

		\paragraph{What are the roles of Eigenvectors and Eigenvalues in PCA?}
			\answer{The eigenvectors are the principal components and the corresponding eigenvalues encode how much variance is explained in that direction.}

		\paragraph{Can you describe applications of PCA?}
			\answer{PCA can be used to decompose images of faces into lower dimensions, change some parameters and then project it back into the original feature space. This can be used to morph images, e.g. to make them more masculine or feminine.}

		\paragraph{What does risk in statistical learning theory mean?}
			\answer{"Risk" is the expectation of misclassifying a sample, which indirectly encodes the generalization abilities of an estimation. If the risk is high, it seems to overfit.}

		\paragraph{How is the true risk different from the empirical risk?}
			\answer{The true risk depends on the underlying probability density via an integral over all data points and cannot be calculated directly, but is the real point of interest. The empirical risk applies the loss function onto some sample data points, giving an estimator for the true risk.}

		\paragraph{What is the learning power of a function approximator?}
			\answer{The learning power expresses how much "capacity" an approximator has. The more learning power an approximator has, the more accurate can the approximations be, but this can also lead to overfitting.}

		\paragraph{What is expressed by a VC-Dimension?}
			\answer{The VC-dimension specifies how much data points can be scattered by a function (or family of functions). For hyperplanes (linear functions), the VC-dimension is always \( \dim(H) + 1 \), where \(H\) is the feature space.}

		\paragraph{Is the VC-Dimension always correlated with the number of parameters?}
			\answer{
				No it is not, a counter example is the function
				\begin{align*}
					f(x, \vec{w}) & = g\big(\sin(w_1 x + w_0)\big) \\
					g(x)          & =
					\begin{cases}
						+1 & \textrm{iff } x > 0    \\
						-1 & \textrm{iff } x \leq 0
					\end{cases}
				\end{align*}
				which has only two parameters but an infinite VC-dimension.
			}
			% end

	\section{Neural Networks}
		\paragraph{How does logistic regression relate to neural networks?}
			\answer{A NN with no hidden layer and just one output neuron equals logistic regression if the output layer has sigmoid as the activation function.}

		\paragraph{How do neural networks relate to the brain?}
			\answer{The brain is made up of neurons that are connected with each other, grouped in so-called "sheets". Every neuron takes inputs from the previous sheet and "fires" if the "value" is above some threshold.}

		\paragraph{What kind of functions can single layer neural networks learn?}
			\answer{Assuming this means "a single hidden layer", it can learn an arbitrary function, but the number of parameters are growing exponentially!}

		\paragraph{Why do two layers help? How many layers do you need to represent arbitrary functions?}
			\answer{Two layers help to reduce the number of parameters needed to approximate a function, which eases the learning. Theoretically, one hidden layer is enough to represent arbitrary functions.}

		\paragraph{Why were neural networks abandoned in the 1970s, and later in the 1990s? Why did neural networks re-awaken in the 2010s?}
			\answer{They were abandoned in the 1970s because of a book noticing that things like the perceptron do not work for simple nonlinear separable data like the XOR. In the 1990s they were abandoned because kernels were much better for optimization. In the 2010s, the big shift from too less data to too many data made them come back as now there is enough data to train such a network.}

		\paragraph{What output layer and loss function to use given the task (regression, classification)?}
			\answer{
				\begin{itemize}
					\item Regression
						\begin{itemize}
							\item Activation function: Linear
							\item Loss function: Squared loss
						\end{itemize}
					\item Classification
						\begin{itemize}
							\item Activation function: Sigmoid for two-class and softmax for multi-class
							\item Loss function: Nonlinear log-likelihood or cross-entropy
						\end{itemize}
				\end{itemize}
			}

		\paragraph{Why use a ReLU activation instead of a sigmoid?}
			\answer{With sigmoid, nearly all regions of the gradient are zero, causing the learning to stop once it reaches that point. In ReLU, only the negative site has a zero gradient, causing the learning to progress better. But the success of ReLU highly depends on the initial weights. A negative initialization can cause "ReLU-networks" to not start to learn.}

		\paragraph{Derive the equations for forward and backwarpropagation for a simple network.}
			\answer{
				Given a simple network with one hidden layer, an input and an output layer, all with just one neuron, the output computes as:
				\begin{equation}
					y = f_2(w_2 f_1(w_1 x_1 + b_1) + b_2)
				\end{equation}
				or stepwise:
				\begin{align}
					y   & = f_2(a_2)      \\
					a_2 & = w_2 z_1 + b_2 \\
					z_1 & = f_1(a_1)      \\
					a_1 & = w_1 x + b_1
				\end{align}

				Take the derivative of the loss w.r.t. \(w_1\) to get the first gradient:
				\begin{align}
					\frac{\partial L}{\partial w_1}   & = L'(y) \frac{\partial y}{\partial w_1}       \\
					\frac{\partial y}{\partial w_1}   & = f_2'(a_2) \frac{\partial a_2}{\partial w_1} \\
					\frac{\partial a_2}{\partial w_1} & = w_2 \frac{\partial z_1}{\partial w_1}       \\
					\frac{\partial z_1}{\partial w_1} & = f_1'(a_1) \frac{\partial a_1}{\partial w_1} \\
					\frac{\partial a_1}{\partial w_1} & = x
				\end{align}
				or more beautiful:
				\begin{equation}
					\frac{\partial y}{\partial w_1} = \frac{\partial L}{\partial y} \frac{\partial y}{\partial a_2} \frac{\partial a_2}{\partial z_1} \frac{\partial z_1}{\partial a_1} \frac{\partial a_1}{\partial w_1}
				\end{equation}
				and w.r.t. \(w_2\) to get the second:
				\begin{align}
					\frac{\partial L}{\partial w_2}   & = L'(y) \frac{\partial y}{\partial w_2}       \\
					\frac{\partial y}{\partial w_2}   & = f_2'(a_2) \frac{\partial a_2}{\partial w_2} \\
					\frac{\partial a_2}{\partial w_2} & = z_1
				\end{align}
				or more beautiful:
				\begin{equation}
					\frac{\partial L}{\partial w_2} = \frac{\partial L}{\partial y} \frac{\partial y}{\partial a_2} \frac{\partial a_2}{\partial w_2}
				\end{equation}
			}

		\paragraph{What is mini-batch gradient descent? Why use it instead of SGD or full gradient descent?}
			\answer{Mini-batch gradient descent uses a subset of the samples for training (another one each iteration), thus reduces the computation cost which is the reason why to use it instead of full gradient descent. Stochastic gradient descent has a much higher variance thus is slow and leads to the parameters "jumping" around.}

		\paragraph{Why neural networks can overfit and what are the options to prevent it?}
			\answer{Typically, a neural network has much more parameters than training data is available which makes it easy for the net to just memorize the data. Some of the options to prevent overfitting are regularization, early stopping (step when the validation error rises again), input noise augmentation (apply some noise to the input), dropout (randomly prune some neurons and train all others).}
			% end

	\section{Support Vector Machines}
		\paragraph{How did learning theory motivate support vector machines?} % TODO: Check.
			\answer{The typical machine learning algorithms try to minimize the empirical risk to lower an upper bound on the true risk. SVMs minimize the confidence interval \( \epsilon(N, p^\ast, h) \) to lower the boundary by minimizing the VC-dimension.}

		\paragraph{What does maximum margin separation mean?}
			\answer{The distance of the decision boundary between the classes to the nearest data points to that decision boundary is called margin. This margin is maximized to generalize as much as possible. Intuition: A decision boundary that is close to one of the classes, but far away from the others seems to not fit as well as a decision boundary that lies directly in the center of the classes, thus maximizing the margin to both classes.}

		\paragraph{Why did the SVM-craze drown the Neural-Networks-craze?} % TODO: Check.
			\answer{Neural networks seem to be too hard to train/optimize, while kernel methods (like in kernel SVMs) are much easier to compute (especially because of quadratic programming). This caused the 2nd from 1994 in neural networks.}

		\paragraph{What is a Kernel?}
			\answer{A kernel \( K(x, y) \) is a function that is equivalent to the scalar product of feature transformations \( \Phi(\cdot) \), so \( K(x, y) = \phi(x)^T \phi(y) \) holds. If such a feature transformation only appears in scalar products, the kernel trick can be used to replace the products with a much easier computable kernel that can even represent feature transformations into an infinite feature space!}

		\paragraph{How can I build Kernels from Kernels?}
			\answer{
				Kernels \( K_1(x, y) \) and \( K_2(x, y) \) can be combined, so all of the following are also valid kernels:
				\begin{gather*}
					c K_1(x, y) \\
					K_1(x, y) + K_2(x, y) \\
					K_1(x, y) \, K_2(x, y) \\
					f(x) \, K_1(x, y) \, f(y)
				\end{gather*}
			}

		\paragraph{What functions does the Radial Basis Function Kernel contain?}
			\answer{N/A} % TODO: Q&A: Answer.

		\paragraph{How does support vector regression work?}
			\answer{N/A} % TODO: Q&A: Answer. (Turn around the cost function?)
			% end

	\section{Kernel Regression and Gaussian Processes}
		\paragraph{Why kernel methods for regression?}
			\answer{Using kernel regression, the regression can work entirely in the feature space and can even consider infinite dimensional feature spaces. Also many other algorithms can be derived from the dual formulation of regression.}

		\paragraph{How do you get from radial basis functions to kernels?}
			\answer{N/A} % TODO: Q&A: Answer.

		\paragraph{What is the role of the two pseudo-inverses in kernel regression?}
			\answer{N/A} % TODO: Q&A: Answer.

		\paragraph{Why are kernel regression methods very computationally expensive?}
			\answer{Because they have to invert an \( N \times N \) matrix, where \(N\) is the number of sample data points.}

		\paragraph{Why is kernel regression the dual to linear regression?}
			\answer{By formulating the dual of linear regression, it can be found that the feature transformations \(\phi(\cdot)\) only appear in scalar product, thus allowing the kernel trick which is then called kernel regression.}

		\paragraph{What is the major advantage of GPs over Kernel Ridge Regression?}
			\answer{Gaussian processes can also gauge the uncertainty of the estimate.}

		\paragraph{Why are GPs a Bayesian approach?}
			\answer{Gaussian processes are Bayesian methods because they involve the construction of a prior distribution.}

		\paragraph{What principle allowed deriving GPs from a Bayesian regression point of view?}
			\answer{N/A} % TODO: Q&A: Answer.

			%\paragraph{How to get the hyperparameters in a Bayesian setup?}
			%\answer{N/A} % TODO: Q&A: Answer.
			% end
			% end
